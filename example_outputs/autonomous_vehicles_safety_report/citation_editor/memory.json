[
  {
    "message": {
      "role": "system",
      "content": "<role>\nYou are a research copy editor working on the final pass on a report. Your task is to verify that every factual statement in the provided draft is backed by evidence that already exists in the session artifacts. Work like a meticulous fact-checker.\n</role>\n\n<requirements>\nCore expectations:\n- Read the draft report carefully, sentence by sentence.\n- Cross-reference each claim with the supplied artifacts (sub-reports, notes, or plan). If a claim has no direct support, flag it and adjust the wording to match what is supported.\n- Insert inline, bracketed numeric citations (e.g., [1], [2]) immediately after the sentences or clauses they support. Re-use numbers when the same source supports multiple claims.\n- Create a \"Sources\" section at the end that enumerates the citations in numeric order. Each entry must include a concise label and the original URL or document reference from the artifacts.\n- Keep the existing structure and headings unless an edit is needed for clarity or accuracy.\n- Do **not** invent new sources, perform fresh web research, or replace the provided evidence.\n- Do **not** refer the sub-reports as sources. These are internal ONLY. You MUST ONLY use the external links as references.\n- Once the citations are added and the text is verified, call the `complete_task` tool with the full revised markdown.\n- Do **not** ask for clarifications or respond with any follow ups. User will **not** respond.\n</requirements>\n\n<output>\nDeliver polished, citation-rich markdown that the user can trust. Do **not** add or remove any content from the original report other than the citations.\n</output>"
    },
    "metadata": {
      "who": "system",
      "when": "2025-11-10T04:34:47.714264+00:00",
      "synthetic": false,
      "kind": "system_prompt"
    }
  },
  {
    "message": {
      "role": "user",
      "content": "You are a meticulous research editor. The lead researcher has finished a draft report for the user. Revise it so that every verifiable fact is supported by inline citations that point to the provided artifacts.\nYour deliverable is the revised report only. Preserve the structure and claims, tighten wording if needed, and insert bracketed numeric citations like [1], [2].\nDo not invent new facts or sources. Cite only from the supplied artifacts and list each citation in a final 'Sources' section with the matching number and URL or document reference.\nAfter verifying the report, return the updated markdown that already includes the citations and the sources section.\n\nResearch plan (for context only – cite from it only if it contains explicit sources):\n```markdown\n## Research Plan for Safety Outcomes of Autonomous Vehicles vs. Human Drivers in Urban North America (2018–2025)\n\n### Assessment and Breakdown\n- **Main Concepts**: Comparative safety metrics (collision, injury, fatality rates per vehicle-mile); variations by location (cities in US/Canada) and conditions (day/night, weather, speed limits); dominant AV incident types (e.g., rear-end collisions, disengagement-related); regulatory reporting gaps affecting data comparability.\n- **Key Entities**: Autonomous vehicles (AVs, focusing on SAE Level 3+ or driverless deployments); human-driven vehicles; urban environments in US (e.g., San Francisco, Phoenix, Austin, Los Angeles) and Canada (e.g., Toronto); incidents by severity (property damage, injury, fatality).\n- **Specific Facts Needed**: Normalized rates (per VMT or VHT); exposure data (miles/hours driven); incident counts by type, severity, location, domain; definitions of terms (disengagement, reportable crash); sources of bias (incomplete reporting, inconsistent definitions).\n- **Temporal/Contextual Constraints**: Data from Jan 1, 2018, to Sep 30, 2025; urban North America only; current as of Nov 2025.\n- **User Priorities**: Quantifiable comparisons with uncertainty quantified; clear tables and definitions; focus on policy-relevant gaps; neutral, evidence-based analysis for analysts/executives.\n\n### Query Type\nBreadth-first query. The topic divides into independent sub-topics: (1) core safety rates comparison, (2) variations by city/domain, (3) incident categories/factors, (4) reporting gaps/biases. These can be researched in parallel without heavy dependencies, enabling efficient coverage of metrics, variations, incidents, and limitations. Synthesis will aggregate into a cohesive report with table and rubric.\n\n### Detailed Research Plan\n- **Subagent Allocation** (4 subagents for medium complexity; parallel deployment to cover distinct components efficiently):\n  1. **Subagent: safety_rates_agent** - Focus: Quantify collision, injury, fatality rates per vehicle-mile (VMT) for AVs vs. human vehicles. Gather exposure-normalized data by severity; include city-level where available (e.g., SF, Phoenix, Toronto). Sources: NHTSA/FARS, California DMV, Arizona DOT, Toronto TTC reports; AV company safety reports (Waymo, Cruise, Uber ATG); peer-reviewed studies (e.g., from TRB, arXiv preprints with methods disclosed). Output: Structured data table with rates, exposure definitions, sources; note uncertainties/gaps. Prioritize 2+ sources per claim; quantify via confidence intervals if available.\n  2. **Subagent: variations_analysis_agent** - Focus: Variations in outcomes by city (US/Canada urban) and domain (day/night, weather, speed limits <25/25-50/>50 mph). Use same sources; extract breakdowns from reports/studies. Output: Summary of patterns (e.g., higher AV rates in rain?); data points by category; highlight data scarcity. Ensure 2+ sources; flag inconsistencies.\n  3. **Subagent: incident_types_agent** - Focus: Dominant AV incident categories (e.g., rear-end while stationary, pedestrian interactions, disengagement-adjacent); contributing factors (e.g., sensor limitations, traffic density). Sources: AV incident databases (NHTSA, DMV disengagement reports), company incident logs, peer-reviewed analyses. Output: List of top categories with frequencies/examples; factors breakdown; compare to human incidents where possible. 2+ sources per type.\n  4. **Subagent: reporting_gaps_agent** - Focus: Regulatory frameworks (e.g., disengagement vs. crash reporting in CA, federal NHTSA rules); definitions inconsistencies; biases (e.g., AVs over-report minor incidents). Sources: Regulatory docs (FMVSS, state AV laws), GAO/CRS reports, studies on data comparability (e.g., RAND, UC Berkeley). Output: Key gaps/limitations; rubric outline for comparability; quantify biases (e.g., % underreported human crashes). 2+ sources.\n\n- **Evaluation of Plan Elements**:\n  - **Independence**: Each subagent handles a distinct key question; minimal overlap (e.g., sources shared but analyses separate).\n  - **Multiple Perspectives**: Subagents instructed to use diverse sources (official, company, academic) for verification.\n  - **Expected Outputs**: Factual summaries with data, sources, uncertainties; aggregate to enable table creation, variation discussion, incident lists, gap analysis.\n  - **Necessity**: Directly maps to objectives/questions; covers must-includes (rates table, definitions, rubric).\n  - **Efficiency**: 4 subagents (no more than needed); parallel execution; if gaps found post-run, iterate with 1-2 more (e.g., fact-check agent).\n\n- **Synthesis Approach**: Compile rates into a Markdown table (AV vs. human, by severity/city); define denominators (e.g., VMT = total miles driven, verified via odometer/GPS); discuss variations/incidents narratively; end with rubric on limits (e.g., AV data skewed by testing vs. full ops). Resolve conflicts via recency/consensus; quantify uncertainty (e.g., \"rates based on 10M AV miles, CI ±20%\"). Ensure neutral tone, no speculation.\n\n- **Execution Strategy**: Deploy all 4 subagents in parallel immediately after plan save. Review outputs for completeness; if needed, deploy 1 serial follow-up (e.g., for specific city data). Synthesize when sufficient (diminishing returns after initial runs). No self-research beyond planning; terminate if core facts covered (e.g., key rates from 3+ cities).\n\nThis plan ensures comprehensive, evidence-based coverage for an excellent report.\n```\n\nDraft final report from the lead researcher:\n```markdown\n## Safety Outcomes of Autonomous Vehicles Relative to Human Drivers in Urban North America (2018–2025)\n\n### Executive Summary\nAutonomous vehicles (AVs), particularly those operating at SAE Level 3 or higher in driverless mode, have demonstrated lower per-vehicle-mile crash rates compared to human-driven vehicles in urban settings across the United States and Canada from January 1, 2018, to September 30, 2025. This analysis focuses on quantifiable safety metrics, variations by location and operating conditions, dominant incident types, and regulatory reporting limitations. Data primarily draws from major deployments in cities like Phoenix, San Francisco, Los Angeles, and Austin, with limited comparable information from Canadian urban areas such as Toronto. While AVs show reductions in injury and serious crashes, uncertainties arise from low cumulative AV mileage (e.g., approximately 96 million driverless miles for leading operators), inconsistent reporting thresholds, and operational design domain (ODD) constraints that limit AV exposure to safer conditions. Overall, AVs appear safer on a per-mile basis where data is available, but direct comparability is challenged by these factors.\n\n### Quantified Comparative Safety Outcomes\nNormalized safety rates for AVs versus human-driven vehicles reveal a pattern of reduced incidents per vehicle-mile traveled (VMT), particularly for injury-related crashes. These comparisons are most robust for leading AV operators in U.S. urban deployments, where large-scale public data exists. Rates are expressed as incidents per million vehicle-miles traveled (IPMM), a standard normalization to account for exposure differences. For context, national human-driven benchmarks from federal data show approximately 0.75 injured persons per million VMT and 0.0126 fatalities per million VMT in 2023, though these are person-level and not directly event-based.\n\nAV rates are derived from driverless operations (e.g., Waymo's rider-only mode), which accumulated around 96 million miles through mid-2025 across multiple cities. Human benchmarks are location-matched surface-street rates from police reports in the same geographies. Key findings include substantial reductions in any-injury crashes (up to 80% lower for AVs) and serious-injury-or-worse events (over 90% lower). Fatalities in AV operations are rare, with zero reported in the largest datasets, though high-profile testing incidents (e.g., a 2018 pedestrian fatality) highlight early risks. Uncertainty is moderate for injury rates due to sufficient sample sizes but high for fatalities given low event counts; confidence intervals for AV rates are typically ±20-30% based on published analyses.\n\n#### Definitions of Rate Denominators\n- **Vehicle-Miles Traveled (VMT)**: The total distance traveled by AVs or human-driven vehicles, measured via GPS, odometer, or telemetry systems. For AVs, this excludes human-driven test miles where possible, focusing on driverless (autonomous) operations.\n- **Incidents per Million Vehicle-Miles Traveled (IPMM)**: Calculated as (number of incidents / total VMT) × 1,000,000. Incidents are categorized by severity: property-damage-only (PDO, no injuries), any-injury-reported (at least one injury noted in reports), serious-injury-or-worse (hospitalization or fatality), and fatalities (death within 30 days). Denominators for human benchmarks use city-specific VMT estimates from traffic data, adjusted for surface streets to match AV ODDs.\n\n| Metric/Severity                  | AV Rate (IPMM) | Human Rate (IPMM) | Key Cities/Period          | Notes/Uncertainty |\n|----------------------------------|----------------|-------------------|----------------------------|-------------------|\n| Any-Injury-Reported Crashes     | 0.41–0.80     | 2.80–3.96        | Phoenix, SF, LA, Austin (2018–June 2025) | AV reductions ~80%; CI ±25% due to 7–96M AV miles; not statistically significant in low-exposure cities like Austin. |\n| Serious-Injury-or-Worse Crashes | 0.02          | 0.23             | Multi-city (2018–June 2025) | Over 90% reduction; low AV counts yield wide CIs (±50%). |\n| Airbag-Deployment Crashes       | 0.35          | 1.65             | Multi-city (2018–June 2025) | Proxy for reportable impact; AV ~79% lower. |\n| Police-Reportable Crashes       | 2.10          | 4.68             | Multi-city (up to Oct 2023) | AV ~55% lower; based on 7M AV miles. |\n| Fatalities                      | 0.00          | 0.0126 (national)| Multi-city (2018–Sep 2025) | Zero in driverless ops; excludes rare testing fatalities; high uncertainty from small samples. |\n\nData gaps include limited AV exposure in Canada (e.g., Toronto: <1M driverless miles publicly reported, insufficient for robust rates) and underreporting in human benchmarks due to voluntary police filings. Rates for other operators (e.g., Cruise) are less reliable due to smaller disclosures and enforcement-noted incompleteness.\n\n### Variations by City and Operating Domain\nSafety outcomes vary significantly by urban location and environmental conditions, reflecting differences in traffic density, infrastructure, and AV operational limits. In Phoenix, AVs benefit from expansive, less congested roads, yielding the lowest injury rates (0.63 IPMM any-injury vs. 2.06 human benchmark). San Francisco shows higher AV rates (0.90 IPMM any-injury vs. 7.93 human) due to denser, pedestrian-heavy environments, though still a ~89% reduction. Los Angeles and Austin exhibit low serious-crash rates (0.00 IPMM in LA), but Austin's small AV mileage (~1M miles) limits statistical confidence. Toronto lacks sufficient driverless VMT for city-specific rates; municipal pilots focus on low-speed shuttles with no large-scale crash data comparable to U.S. robotaxi fleets.\n\nBy operating domain, AV incidents cluster in low-risk conditions aligned with ODDs: ~65% on roads with speed limits ≤25 mph, 93% on dry pavement, and 60% in daylight. Nighttime (dark conditions) accounts for ~36% of reports, but without VMT stratified by lighting, per-mile risks cannot be quantified—proportions suggest AVs avoid unlit operations. Weather variations are minimal (7% wet roads, <1% snow), as AVs curtail services in adverse conditions, potentially biasing rates lower. Speed bands show higher human crash rates above 50 mph, but AVs rarely operate there, creating a comparability gap. Uncertainty is high for domain-specific rates (±40-60%) due to absent exposure breakdowns; patterns indicate AVs excel in low-speed urban cores but lack data for highways or inclement weather.\n\n### Primary Incident Categories and Contributing Factors\nAV incidents in urban North America predominantly involve low-severity events, often with the AV as the struck party. The top categories, based on analyses of over 2,000 reported events, include:\n\n- **Rear-Ended While Stationary (~40-50% of reports)**: AVs stopped at lights or yielding are hit from behind by human drivers. This dominates due to AVs' conservative behaviors (e.g., full stops). Contributing factor: Human error in tailgating; AVs rarely at fault.\n  \n- **AV-Initiated Rear-Ends (~20-30%)**: AVs collide with leading vehicles during acceleration or in stop-and-go traffic. Factors include perception delays in dense flows or overly cautious gap maintenance, leading to late responses.\n\n- **Intersection/Turning Conflicts (~15-20%)**: Collisions during turns, yields, or cut-ins, elevated at dawn/dusk (5x higher odds vs. humans). Factors: Complex signal prediction and VRU (vulnerable road user) detection failures.\n\n- **VRU Incidents (~10-15%)**: Pedestrian or cyclist strikes/near-misses, including sensor misses (e.g., a 2023 dragging event). Factors: Occlusion in urban clutter or classification errors; ~2x higher odds during turns.\n\n- **Sideswipes/Merges (~5-10%)** and **Fixed-Object Strikes (~5%)**: Lane-change rubs or curb/barrier contacts from path-planning edge cases.\n\n- **Disengagement-Adjacent (~5%)**: Crashes during human intervention, often in edge scenarios like construction.\n\nCompared to humans, AVs show 50-90% fewer incidents per mile overall, but higher relative risk in turns and low-light (2-5x odds in matched studies). Factors like ODD limits (e.g., no highways) and telematics enhance detection but inflate minor reports. Uncertainty stems from redactions (~30% of narratives obscured) and small samples for rare events (e.g., VRU: <100 cases).\n\n### Regulatory Reporting Gaps Affecting Comparability\nRegulatory frameworks differ across jurisdictions, leading to biases in AV-human comparisons. Federal U.S. rules (NHTSA Standing General Order) mandate reporting crashes with injury/fatality or airbag deployment for AVs/ADAS, but states like California require AV manufacturers to report all disengagements (human takeovers, even non-crash) and collisions causing >$1,000 damage. Arizona and Texas focus on testing permits with voluntary incident logs, while Ontario's pilot program requires safety reports but lacks standardized crash thresholds. These inconsistencies mean AVs over-report minor events (e.g., California's ~5 disengagements per 1,000 miles vs. NHTSA's ~0.04 crashes per 1,000 miles for similar exposure), potentially inflating AV incident counts by 5-10x relative to human data, where only severe crashes are systematically captured.\n\nKey gaps include:\n- **Inconsistent Definitions**: \"Disengagement\" (CA: any safety-critical takeover) vs. \"reportable crash\" (NHTSA: injury/airbag threshold); this captures non-events for AVs, biasing counts upward by ~20-30% in state data.\n- **Exposure Undercount**: AV VMT often limited to testing/public ops (~10-20M total across operators), vs. billions for humans; low samples widen CIs (±50% for rare events).\n- **Voluntary/Redacted Reporting**: ~40% of state logs redacted; human crashes underreported (only 50-60% police-filed), while AV telematics ensures near-100% capture.\n- **Geographic Fragmentation**: No unified Canada-wide system; Toronto pilots underreport vs. U.S. states.\n\n#### Rubric for Comparability Limits\n1. **Threshold Mismatch (High Impact)**: AVs report minor disengagements/crashes absent in human data, overestimating AV risk by 5x for low-severity events; adjust via severity filtering.\n2. **Exposure Bias (Medium-High Impact)**: AV ODDs exclude high-risk domains (e.g., rain, >50 mph), understating human-AV differences; normalize only within shared conditions.\n3. **Data Completeness (Medium Impact)**: Redactions/underreporting affect ~30-40% of AV logs and >50% of human minor crashes; cross-verify via multiple sources.\n4. **Sample Size (Variable Impact)**: AV miles <0.01% of human totals; prioritize operators with >10M miles (e.g., Waymo) and quantify uncertainty via CIs.\n\nThis rubric highlights that while AVs show promising safety gains, unaddressed gaps prevent definitive policy conclusions without standardized reporting by late 2025.\n```\n\nSupporting artifacts with evidence:\n--- Artifact 1: sub_report_incident_types_agent_call_AZNyxGinspXkb4Ah7DsGEL5F_step13.md ---\n```markdown\nSub-report: Primary AV incident categories and contributing factors — Urban North America, 2018–2025 Q3\n\nObservations\n- Research subagent - 2025-11-10T04:32:00Z: Scope & sources used — I reviewed NHTSA SGO ADS incident records (machine-readable CSV), California DMV OL‑316 collision report listings (manufacturer PDFs), Waymo corporate safety disclosures and peer‑reviewed analyses (Kusano et al., Waymo safety hub, Swiss Re blog), a matched case-control peer‑review (Nature Communications), a latent‑class analysis of CA DMV reports (Journal of Safety Research), and regulatory/enforcement documents (Cruise consent order, DOJ press release). Key source URLs used: NHTSA ADS CSV (https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv) [Source: https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv]; CA DMV collision reports index (https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/) [Source: https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/]; Waymo safety hub (https://waymo.com/safety/impact/) [Source: https://waymo.com/safety/impact/]; Kusano et al., Traffic Injury Prevention (2024) (https://www.tandfonline.com/doi/full/10.1080/15389588.2024.2380786) [Source: https://www.tandfonline.com/doi/full/10.1080/15389588.2024.2380786]; Nature Communications matched case-control (2024) (https://www.nature.com/articles/s41467-024-48526-4) [Source: https://www.nature.com/articles/s41467-024-48526-4]; Latent class analysis (Journal of Safety Research, 2025) (https://www.sciencedirect.com/science/article/pii/S0022437524001634) [Source: https://www.sciencedirect.com/science/article/pii/S0022437524001634]; Cruise consent order (NHTSA PDF) (https://www.nhtsa.gov/sites/nhtsa.gov/files/2024-09/cruise-consent-order-2024-web.pdf) [Source: https://www.nhtsa.gov/sites/nhtsa.gov/files/2024-09/cruise-consent-order-2024-web.pdf]; DOJ press release re: Cruise DPA (https://www.justice.gov/usao-ndca/pr/cruise-admits-submitting-false-report-influence-federal-investigation-and-agrees-pay) [Source: https://www.justice.gov/usao-ndca/pr/cruise-admits-submitting-false-report-influence-federal-investigation-and-agrees-pay].\n\nDecisions\n- Research subagent - 2025-11-10T04:32:00Z: Taxonomy & framing — I mapped reported events into a pragmatic incident taxonomy used in the literature and regulatory narratives for urban ADS operations: (A) being rear‑ended while stopped or slowing (AV as stationary victim), (B) AV rear‑ending or striking another vehicle while moving (AV-initiated contact), (C) intersection/turning conflicts (including cutting/turning and red‑light/stop sign interactions), (D) vulnerable road user (VRU) incidents — pedestrian/cyclist strikes or detection failures and near‑misses, (E) sideswipe/merging/ lane‑change conflicts, (F) fixed/object strikes or roadway boundary contacts, and (G) disengagement or operator‑control transitions that precede collisions. I validated the taxonomy against cluster analyses and case studies in the literature and against SGO/OL‑316 narratives [Source: https://www.sciencedirect.com/science/article/pii/S0022437524001634] [Source: https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv].\n\nFindings — Top incident categories (ranked qualitatively by prevalence in the sources above and with example references)\nNote: available public datasets are heterogenous and partially redacted; exact national counts by category require full structured parsing of NHTSA/DMV CSVs/PDFs. Below I report conservative, source‑anchored summaries and selected examples.\n\n1) Rear‑ended while stopped (AV stationary, hit by another road user)\n- Evidence & prevalence: Frequent in CA DMV narratives and appears repeatedly in SGO ADS CSV 'Narrative' examples (multiple monthly entries describing AV stopped and struck from behind) [Source: https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv] [Source: https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/].\n- Example: Waymo report (Aug 2025) describes an AV stopped in a right‑turn lane that was struck in the rear by an SUV while Waymo ADS was engaged [Source: https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv].\n\n2) AV rear‑ending another vehicle (AV contact while proceeding/starting from stopped)\n- Evidence & prevalence: Identified as a common cluster in CA report analyses (cluster labelled ‘rear‑end collisions after the speed change of AV’ in latent‑class analysis) and present in SGO narratives [Source: https://www.sciencedirect.com/science/article/pii/S0022437524001634] [Source: https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv].\n- Mechanisms: Often associated with AV speed control (initial acceleration/slow follow), sensor/perception ambiguities in dense stop‑and‑go traffic, or conservative gap acceptance leading to late acceleration responses [Source: https://www.sciencedirect.com/science/article/pii/S0022437524001634].\n\n3) Intersection / turning conflicts (including cut‑ins, failed yields and turn‑related collisions)\n- Evidence & prevalence: Nature Communications matched‑case study and other papers identify turns and intersection maneuvers as a relatively higher‑risk context for ADS vs human drivers; the Nature study reports AV accidents were more likely under turning conditions (odds ratio ≈ 1.98) and at dawn/dusk (odds ratio ≈ 5.25) relative to matched human‑driver cases [Source: https://www.nature.com/articles/s41467-024-48526-4]. CA DMV narratives also frequently record collisions during turning or at intersections [Source: https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/].\n\n4) Vulnerable road user (VRU) incidents — pedestrian/cyclist detection failures, run‑overs, dragging events, and near‑misses\n- Evidence & prevalence: High regulatory and investigative attention — Cruise’s Oct 2023 pedestrian run‑over and dragging incident (subject of NHTSA inquiry, consent order, and DOJ deferred‑prosecution action) is a high‑profile example of detection/response failure and reporting problems [Source: https://www.nhtsa.gov/sites/nhtsa.gov/files/2024-09/cruise-consent-order-2024-web.pdf] [Source: https://www.justice.gov/usao-ndca/pr/cruise-admits-submitting-false-report-influence-federal-investigation-and-agrees-pay]. CA DMV reports and SGO CSV entries include pedestrian/cyclist‑involved incidents and near‑miss narratives [Source: https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/] [Source: https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv].\n- Example quantification (company/claims level): Waymo + Swiss Re analysis across 25.3M autonomous miles found very low counts of liability claims (9 property‑damage claims, 2 bodily‑injury claims) and large reductions vs human baselines — used as a company‑level safety benchmark but not a taxonomy of crash types [Source: https://waymo.com/blog/2024/12/new-swiss-re-study-waymo] [Source: https://waymo.com/safety/impact/].\n\n5) Sideswipe / merging / lane‑change conflicts\n- Evidence & prevalence: Appears in CA DMV clusters and SGO narratives (including parking/low‑speed sideswipe clusters in LCA) [Source: https://www.sciencedirect.com/science/article/pii/S0022437524001634] [Source: https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv].\n\n6) Fixed‑object / curb / boundary contacts\n- Evidence: Reported repeatedly in CA narratives and SGO CSV (AV contacting poles/curbs/guardrails or road furniture in urban environments) — often lower severity but indicative of localization/path‑planning edge cases [Source: https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv] [Source: https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/].\n\n7) Disengagement / operator transition preceded collisions\n- Evidence: Several SGO/OL‑316 narratives describe operator intervention, braking or steering by a human during or immediately after the event; regulatory documents emphasize that some collisions occur during or immediately after an operator takes control or when the ADS was transitioning [Source: https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv] [Source: https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/].\n\nContributing factors — breakdown with quantification where available\n- Lighting/time-of-day (dawn/dusk): Nature Communications found a marked increase in AV accident likelihood at dawn/dusk (≈5.25× higher odds compared to matched human cases) [Source: https://www.nature.com/articles/s41467-024-48526-4].\n- Turning maneuvers: Nature reported turning conditions had ≈1.98× higher odds for AV accidents than human drivers in matched comparisons [Source: https://www.nature.com/articles/s41467-024-48526-4].\n- Speed change / stop‑and‑go acceleration profiles: The latent‑class analysis of CA DMV crash narratives identified a dominant cluster characterized as ‘rear‑end after AV speed change,’ linking AV speed-control behavior to a substantial share of collisions in that sample (clustering over a 308‑case CA dataset) [Source: https://www.sciencedirect.com/science/article/pii/S0022437524001634].\n- External actors’ failure to yield / human driver fault (AV as victim): CA DMV and SGO narratives repeatedly show other drivers failing to yield or driving into the AV’s path — a commonly reported causal text string in narratives [Source: https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/] [Source: https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv].\n- Perception/detection limits for VRUs: High‑profile Cruise case and other narratives point to sensor/perception misses or classification failures as critical factors in VRU incidents; regulatory documents and the DOJ press release detail concrete failures to detect and to report accurately [Source: https://www.nhtsa.gov/sites/nhtsa.gov/files/2024-09/cruise-consent-order-2024-web.pdf] [Source: https://www.justice.gov/usao-ndca/pr/cruise-admits-submitting-false-report-influence-federal-investigation-and-agrees-pay].\n- Reporting quality, redactions, & data heterogeneity: CA DMV reports are often redacted for PII; SGO reports are voluntary in structure (narratives vary) and NHTSA has noted caveats in available SGO reporting (unverified initial reports, redactions) — these limit precise national quantification without programmatic parsing and harmonization [Source: https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/] [Source: https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv].\n\nComparison to human drivers (where available)\n- Aggregated safety impact (miles‑normalized): Waymo’s peer‑reviewed RO analysis (Kusano et al.) and the Waymo safety hub show ADS (Waymo Driver) crash rates per million miles substantially lower than human benchmarks for serious injuries, airbag deployments, and any‑injury crashes (e.g., Waymo RO any‑injury IPMM 0.80 vs human benchmark 3.96 in combined locations reported on Waymo hub; Kusano et al. report ~0.6 IPMM ADS any‑injury vs 2.80 IPMM human benchmark for their 7.14M‑mile sample) — these comparisons are mile‑normalized and not a direct decomposition by crash category, but they provide evidence that ADS operations to date have lower per‑mile injury crash rates in Waymo’s operating cities [Source: https://waymo.com/safety/impact/] [Source: https://www.tandfonline.com/doi/full/10.1080/15389588.2024.2380786].\n- Case‑matched differences by scenario: Nature Communications matched case‑control shows that, overall, ADS‑equipped vehicles have lower accident odds in many scenarios but higher odds in specific contexts (dawn/dusk and turning) — indicating scenario‑dependent relative risk vs human drivers [Source: https://www.nature.com/articles/s41467-024-48526-4].\n- Company‑level claims analysis (insurance proxy): Waymo + Swiss Re analysis over 25.3M miles reported large reductions in property‑damage and bodily‑injury claim frequencies vs human baselines (88% PD reduction; 92% BI reduction), but this is an insurance‑claims proxy and does not specify a breakdown by crash type [Source: https://waymo.com/blog/2024/12/new-swiss-re-study-waymo] [Source: https://waymo.com/safety/impact/].\n\nData gaps, limitations, and quantification caveats\n- Heterogeneous reporting and redactions: CA DMV PDFs are often redacted; SGO CSV narratives are variable and may contain PII redactions and “unknown” flags — both limit automated classification without careful preprocessing [Source: https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/] [Source: https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv].\n- Company sample bias: Waymo analyses reflect their operating cities and fleet ODDs and should not be generalized nationwide without adjustment; similarly, Cruise regulatory materials highlight under‑reporting and reporting‑quality problems that reduce confidence in aggregated counts absent independent verification [Source: https://waymo.com/safety/impact/] [Source: https://www.nhtsa.gov/sites/nhtsa.gov/files/2024-09/cruise-consent-order-2024-web.pdf].\n- Lack of harmonized, category‑level national counts: Peer‑reviewed analyses use compiled datasets (e.g., Nature used 2,100 AV records) and local DMV files; however, there is not yet a single authoritative, fully harmonized national AV crash ontology covering 2018–2025Q3 that reports category percentages — producing exact percentage splits requires programmatic parsing of SGO CSV and CA OL‑316 PDFs and mapping of narrative text to a standard taxonomy (this parsing remains to be completed) [Source: https://www.nature.com/articles/s41467-024-48526-4] [Source: https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv].\n\nConclusions (condensed)\n- The dominant incident types in urban ADS operations 2018–2025Q3 (by frequency in public narratives and cluster analyses) are: (1) being rear‑ended while stopped, (2) AV‑rear‑end collisions associated with AV speed changes, (3) intersection/turn‑related conflicts, (4) VRU‑related incidents (pedestrians/cyclists — including high‑profile detection failures), (5) sideswipe/merging conflicts, (6) fixed‑object/curb strikes, and (7) collisions occurring during or immediately after human disengagement/transition. Each category is supported by at least two source types in the public record (SGO CSV entries and CA DMV PDFs plus peer‑reviewed cluster/matched‑case analyses and company/regulatory disclosures) [Source: https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv] [Source: https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/] [Source: https://www.sciencedirect.com/science/article/pii/S0022437524001634] [Source: https://www.nature.com/articles/s41467-024-48526-4].\n\nFollow‑ups (for the lead researcher — I executed data collection and this is the sub‑report to integrate)\n- Research subagent - 2025-11-10T04:32:00Z: Deliverable status — Subtask complete: I assembled taxonomy, sourced supporting evidence, and quantified scenario‑level risk where peer‑reviewed studies provided numbers (dawn/dusk odds, turning odds, miles‑normalized IPMM benchmarks). Key remaining technical task for final lead analysis: programmatic parsing & classification of the full SGO ADS CSV plus batch extraction of CA DMV OL‑316 PDF narratives to produce precise frequency counts and percentage breakdowns for 2018–2025Q3 (this requires OCR/PII‑aware parsing and mapping to the taxonomy). Primary data files to parse: SGO ADS CSV (https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv) and CA DMV OL‑316 PDF set (index at https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/) [Source: https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv] [Source: https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/].\n\nEnd of sub‑report.\n```\n--- Artifact 2: sub_report_reporting_gaps_agent_call_9uZZPZPkBdeXIEC0Jtcs0OIp_step6.md ---\n```markdown\nSub-report prepared: regulatory reporting gaps for AV safety (North America, 2018–2025 Q3). Contains: 1) Key definitions/frameworks summary with source citations; 2) List of gaps/biases with at least two sources per gap and quantified illustrative calculations where data allow; 3) A short 4-point rubric of comparability challenges. Sources used: NHTSA Standing General Order (SGO) crash reporting page and Third-Amended SGO PDF (2025); NHTSA ADAS Level 2 Summary Report (June 2022); NHTSA Automated Vehicles Report to Congress (2023); NHTSA crash-data systems page; California DMV disengagement pages, CSVs and 2023 news release (9,068,861 miles); Ontario Automated Vehicle Pilot regulation and program pages; Arizona DOT autonomous vehicle testing pages; Texas DOT CAV Task Force pages; RAND report \"Measuring Automated Vehicle Safety: Forging a Framework\" (RR2662); Brookings \"state of self-driving car laws\" (2018); CRS insight IN11749. The sub-report is ready to hand off to the lead agent.\n```\n--- Artifact 3: sub_report_safety_rates_agent_call_WtfatwPQybKGVYHgqwFnh4Tb_step9.md ---\n```markdown\nSub-report: AV vs Human crash/injury/fatality rates per VMT (Jan 1, 2018 – Sep 30, 2025) — urban North America (San Francisco, Phoenix, Los Angeles, Austin, Toronto, Phoenix)\n\n1) Definitions (used throughout)\n- Vehicle-mile traveled (VMT): total miles driven by the vehicle(s) measured by odometer/GPS/vehicle telemetry. Rate convention used here: incidents per million vehicle-miles traveled (IPMM) = (number of incidents / VMT) * 1,000,000.\n- Metrics and severity categories used in sources and in this report:\n  - Property-damage-only (PDO): crash reported with property damage and no reported injury.\n  - Any-injury-reported crash: police or official report indicates at least one injured person (any severity).\n  - Serious-injury-or-worse: crash with serious injury (hospitalization) or fatality.\n  - Fatality: crash resulting in one or more deaths (FARS/NHTSA definitions where applicable).\n\n2) Key quantitative results (table of rates). Notes: where possible I report multiple independent source values for the same metric (different datasets / periods). All rates are incidents per million vehicle miles (IPMM). \"AV\" entries primarily reflect driverless/\"rider-only\" (RO) ADS operations (Waymo); other AVs have much smaller/publicly limited exposure and are indicated separately. \"Human benchmark\" uses the human-surface-street benchmark used by Waymo (city-specific police/VMT-based benchmarks) and, where noted, national NHTSA rates for context.\n\nTable (selected metrics; city / period shown):\n- Any-injury-reported crash rate (IPMM):\n  - AV (Waymo rider-only, combined locations through June 2025): 0.80 IPMM [1].\n  - AV (Waymo rider-only, 7.14M miles through Oct 2023; peer-reviewed analysis): 0.41 IPMM [2].\n  - Human benchmark (Waymo city surface-street benchmark, combined locations): 3.96 IPMM [1].\n  - Human benchmark (alternative peer-reviewed benchmark used in Kusano et al. paper): 2.80 IPMM [2].\n  - Context (national injured-persons rate from NHTSA Traffic Safety Facts 2023): 75 injured persons per 100M VMT = 0.75 injured persons per M VMT (note: injured persons vs crash events differ in definition) [7].\n  - Cities/data period: Phoenix, San Francisco, Los Angeles, Austin — AV data through June 2025 (Waymo hub); Kusano et al. 7.14M miles through Oct 2023 [1][2].\n  - Sources (minimum two independent): Waymo Safety Impact data hub [1]; Kusano et al. peer-reviewed study / Waymo research paper (Traffic Injury Prevention) [2]; NHTSA Traffic Safety Facts (national context) [7].\n\n- Serious-injury-or-worse crash rate (IPMM):\n  - AV (Waymo combined): 0.02 IPMM [1].\n  - Human benchmark (Waymo combined): 0.23 IPMM [1].\n  - Kusano et al. (7.14M miles) report statistically significant reductions in serious-injury-class outcomes for combined locations (ADS 0.41 any-injury; police-reported crash rates 2.1 vs 4.68 for human benchmark — see paper for which outcome each refers to) [2].\n  - Cities/data period: Phoenix, San Francisco, Los Angeles, Austin; Waymo hub through June 2025; Kusano et al. through Oct 2023 [1][2].\n  - Sources: Waymo Safety Impact [1]; Kusano et al. peer-reviewed study [2].\n\n- Airbag-deployment / police-reportable / property-damage proxies (IPMM):\n  - Airbag-deployment crashes (Waymo combined): 0.35 IPMM vs benchmark 1.65 IPMM [1].\n  - Police-reportable crashed-vehicle rate (Kusano et al., ADS 7.14M): 2.1 IPMM for ADS vs 4.68 IPMM benchmark (police-reportable crashes) [2].\n  - Sources: Waymo hub [1]; Kusano et al. [2].\n\n- Fatalities (IPMM):\n  - AV (Waymo rider-only): reported fatal crashes are extremely rare/zero in the Waymo rider-only public datasets used for the analyses above (Waymo reports serious-injury-or-worse 0.02 IPMM; counting of fatalities specifically in RO miles over the analyzed periods shows zero fatal crashes attributable to Waymo RO operations in the published Waymo analyses) [1][2].\n  - Human context (national): 1.26 fatalities per 100M VMT in 2023 = 0.0126 fatalities per M VMT [7].\n  - Note: the Uber Tempe pedestrian fatality (Mar 2018) is a high-profile AV-involved fatality in the U.S. testing era; it is an example of a testing fatality within the 2018–2025 window but represents a single event from early-stage testing and is widely documented in NHTSA records and news reporting (not used to compute fleet-level IPMM above) [6][3].\n  - Sources: Waymo hub and Kusano et al. (Waymo dataset) [1][2]; NHTSA national fatality statistics [7]; NHTSA press materials and SGO dataset and California DMV incident reports for individual AV fatality coverage [6][3].\n\n3) Narrative summary of findings, uncertainties, and gaps\n- Main quantitative finding (based on available public, city-level driverless ADS data): Waymo’s publicly shared rider-only (driverless) crash rates (measured as incidents per million miles) are substantially lower than the human-surface-street benchmarks in the same urban areas for multiple outcomes (any-injury-reported crashes, serious-injury-or-worse, airbag-deployment and police-reportable crash rates). Example figures: Waymo any-injury-reported combined = 0.80 IPMM vs human benchmark 3.96 IPMM (Waymo hub, through June 2025) [1]; Kusano et al. peer-reviewed comparison on a smaller but independent dataset (7.14M miles through Oct 2023) found ADS any-injury-reported rate 0.41 IPMM vs a human benchmark of 2.80 IPMM (statistically significant reductions reported) [2]. Both the Waymo dashboard and the Kusano et al. paper report statistical uncertainty and confidence intervals for their estimates; Waymo provides 95% CIs on its IPMM estimates in the Safety Impact hub and Kusano et al. report significance testing and CI methodology in the peer-reviewed paper [1][2].\n\n- Important caveats and uncertainty:\n  - Exposure (VMT) differences: AV fleets today (2018–2025) have driven orders of magnitude fewer miles in public driverless operations than the human-driven vehicle fleet. Waymo’s RO exposure (96M RO miles through June 2025 per Waymo’s hub) is large by AV standards but small relative to total urban VMT; the sample sizes for other AV operators are much smaller or not publicly reported, reducing precision for cross-fleet comparisons [1][5]. Use of per-mile normalization reduces but does not eliminate concerns about representativeness of where and how AV miles are driven (e.g., constrained operating design domains, route selection, speed and time-of-day limits).\n  - Definition and reporting differences: sources differ in exact outcome definitions (\"any injury reported\" vs police-reported crashes vs airbag deployments vs severity levels). Waymo’s benchmark methodology adjusts for location and exposure and is documented on the Waymo Safety Impact hub; Kusano et al. provide a peer-reviewed method for benchmarking; national NHTSA tables use different sampling (CRSS/FARS) and report person-level counts. Direct apples-to-apples matching across all datasets is therefore imperfect; where possible I present the officially reported IPMM values and note definition differences [1][2][7].\n  - Potential reporting bias and completeness: NHTSA’s Standing General Order (SGO) requires reporting from ADS/ADAS manufacturers and operators, and NHTSA publishes SGO incident CSV files — but compliance and completeness have been topics of regulatory enforcement (e.g., NHTSA consent order with Cruise for incomplete reporting), and SGO files themselves are incident-level reports (not aggregated rates) [6][9]. California DMV requires AV companies to submit collision and mileage/disengagement reports; these are essential but do not capture private testing miles outside the reporting period/region and may not be fully standardized across operators [3][5]. The Cruise consent-order action shows regulators have found incomplete reporting in industry submissions, which increases uncertainty when aggregating cross-company results [8][9].\n  - Small-number effects: many operators have driven very small driverless VMT totals, producing wide confidence intervals and in many cases rates that are not statistically distinguishable from human benchmarks; Waymo’s larger exposure yields tighter CIs and statistically significant reductions in several outcomes, but this is largely a Waymo-specific result to date [1][2].\n\n- Other AV operators / jurisdictional notes:\n  - California DMV publishes collision reports and annual mileage/disengagement CSVs for AV testers/deployers; these show that multiple companies test/deploy in California but with widely varying mileage totals — the DMV reported a record ~9 million test miles among permit holders in one 12-month period (Feb 2024 release), and the DMV’s collision-report pages list the detailed incident PDFs; these data are essential for cross-company counting but must be aggregated carefully and combined with exposure to derive IPMM rates [4][3][5].\n  - NHTSA SGO provides incident-level public CSVs with reports submitted under the SGO; the dataset is a required regulatory record and is useful for counting reported incidents by reporting entity, but it does not by itself contain consolidated exposure (miles) per operator. Analyses that combine SGO incident counts with operator mileage disclosures (e.g., company transparency reports or state DMV mileage reports) are necessary to compute IPMM for other operators; those combined computations require careful matching and often are not available in a standardized form for every company [6][9].\n  - Cruise: regulatory actions (NHTSA consent order) document incomplete reporting for some incidents; Cruise’s data and reporting history therefore have additional uncertainty, complicating cross-fleet rate comparisons [8]. California DMV collision PDFs list many incidents reported by Cruise and other operators; however, exposure (miles) for Cruise’s driverless operations is less consistently published than Waymo’s, so robust IPMM estimates for Cruise are not presently reproducible from public sources without additional data [3][5][8].\n  - Toronto (Canada): at present there is limited public driverless-ADS rider-only VMT in Toronto available to compute robust AV IPMMs. The City of Toronto produces analyses of ride-hail and PTC vehicle collision rates per vehicle-kilometre — e.g., PTC collisions were reported as ~3.8 collisions per 10 million km for a recent multi-year period (2020–2023) — but those figures cover human-driven platform vehicles, not driverless AVs; they are provided here for local context only and show the difficulty of obtaining true driverless-ADS exposure data in many Canadian municipalities [10].\n\n4) Main limitations and recommended interpretation\n- The strongest, most-robust AV vs human rate comparisons to date come from Waymo’s rider-only datasets (large exposure, transparent methodology) and independent peer-reviewed analyses of those datasets; results from other AV operators are limited by small exposure, variable transparency, and known reporting-completeness issues in some cases (NHTSA enforcement actions). Therefore fleet-level statements that generalize across all AV operators should be made with caution.\n- Numerical head-to-head comparisons reported here rely on the explicit definitions and measurement choices made by the cited sources; differences in those definitions (e.g., crash event vs injured person) are noted and can materially affect direct numeric equivalence.\n\n5) Short, neutral conclusion (facts-only)\n- For the cities and period where large driverless-ADS exposure exists (Waymo rider-only operations in Phoenix, San Francisco, Los Angeles, Austin), publicly reported IPMM rates for multiple outcomes (any-injury-reported crashes, police-reportable crashes, airbag deployments, and serious-injury-or-worse) are numerically lower for Waymo’s rider-only operations than the human-surface-street benchmarks used in the same geographies and periods. This finding is supported by Waymo’s Safety Impact hub (which reports IPMM and 95% CIs) and an independent peer-reviewed analysis of Waymo RO data (Kusano et al., Traffic Injury Prevention) [1][2].\n- For other AV operators and for driverless operations in many North American cities (including Toronto), publicly available driverless-ADS exposure is much smaller or not reported in a standardized way; this produces large uncertainty and prevents robust, generalizable per-VMT rate estimates for those operators/locations at present. Regulatory datasets (NHTSA SGO incident reports, California DMV collision/mileage reports) are essential for cross-checking but require careful aggregation and may be affected by incomplete reporting for some operators (documented enforcement action vs Cruise) [3][5][6][8][9].\n\n6) References (URLs used to compute / verify numbers presented above; each numbered reference was used in the text above):\n[1] Waymo Safety Impact hub (RO miles and IPMM tables/graphs; includes city breakdowns and 95% CI info) — https://waymo.com/safety/impact/\n[2] Kusano K.D. et al., \"Comparison of Waymo rider-only crash data to human benchmarks at 7.1 million miles\" (Waymo research / Traffic Injury Prevention paper) — https://waymo.com/research/comparison-of-waymo-rider-only-crash-data-to-human/\n[3] California DMV – Autonomous Vehicle Collision Reports page (incident PDFs; repository of collision reports) — https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/\n[4] California DMV news release: \"Autonomous Vehicle Permit Holders Report a Record 9 Million Test Miles in California in 12 Months\" (Feb 2, 2024) — https://www.dmv.ca.gov/portal/news-and-media/news-releases/autonomous-vehicle-permit-holders-report-a-record-9-million-test-miles-in-california-in-12-months/\n[5] California DMV – Disengagement and autonomous mileage reports (CSV datasets and annual mileage files) — https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/disengagement-reports/\n[6] NHTSA – Standing General Order on Crash Reporting (SGO) and SGO data (regulatory reporting requirement for crashes involving ADS/ADAS) — https://www.nhtsa.gov/laws-regulations/standing-general-order-crash-reporting\n[7] NHTSA Traffic Safety Facts / National Statistics (Vehicle miles traveled, fatalities and injured-person counts; used for national context) — https://cdan.nhtsa.gov/tsftables/National%20Statistics.pdf\n[8] NHTSA press release: Consent order with Cruise following incomplete reporting findings (shows regulators discovered incomplete reporting by an AV operator) — https://www.nhtsa.gov/press-releases/consent-order-cruise-crash-reporting\n[9] NHTSA SGO incident CSV (public incident-level file containing reports submitted under SGO) — https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADAS.csv\n[10] City of Toronto documents (ride-hail/PTC collision rates per vehicle-km and Vision Zero reports) — example: \"Transportation Impacts of Vehicle-for-Hire in...\" (background; PTC collision rate) — https://www.toronto.ca/legdocs/mmis/2024/ex/bgrd/backgroundfile-251488.pdf\n\n7) Final notes for lead researcher\n- I used official public sources (Waymo Safety Impact hub, Waymo peer-reviewed research paper, California DMV collision and mileage/disengagement files, NHTSA SGO and Traffic Safety Facts tables, NHTSA press releases). For the strongest AV-vs-human per-VMT comparisons available in the requested urban cities/timeframe, the most robust public exposure-plus-incident datasets and methods are those produced and published by Waymo and the independent peer-reviewed analyses of those data. Other operators’ exposures are smaller and/or incompletely reported publicly; NHTSA enforcement actions have documented incomplete reporting by at least one major operator (Cruise), which increases uncertainty for cross-fleet aggregation. Please incorporate these references and the caveats above when integrating this sub-report into the larger research product.\n\n(End of sub-report)\n```\n--- Artifact 4: sub_report_variations_analysis_agent_call_hbITfqV2UPtOYBWJmDAi76TX_step3.md ---\n```markdown\nSub-report: AV vs Human Safety Outcomes by City and Operating Domain — US/Canada (2018–2025 Q3)\n\nScope and methods (short):\n- Sources used (web-extract results): (A) NHTSA SGO / ADS crash summary PDF (NHTSA data summary, July 2024) [https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf]; (B) California DMV Autonomous Vehicle collision reports page [https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/]; (C) Waymo peer-reviewed analysis (Kusano et al.) comparing rider-only crash data to human benchmarks [https://waymo.com/research/comparison-of-waymo-rider-only-crash-data-to-human/]; (D) Waymo Safety Impact / Data Hub (RO miles & city breakdown through June 2025) [https://waymo.com/safety/impact/ and https://waymo.com/blog/2024/09/safety-data-hub/]; (E) IIHS analysis on limits of AVs (2020) [https://www.iihs.org/news/detail/self-driving-vehicles-could-struggle-to-eliminate-most-crashes]; (F) Cruise blog and public disclosures about incidents and third-party findings (Cruise) [https://getcruise.com/news/blog/2024/cruise-releases-third-party-findings-regarding-october-2/]; (G) City of Toronto automated vehicle pilot background (Toronto documents) [https://www.toronto.ca/legdocs/mmis/2025/ie/bgrd/backgroundfile-254933.pdf].\n\n(Each factual claim below cites at least two of the above sources; where a claim uses data from a web_extract call the specific URL used is included after the claim as [Source: <url>].)\n\n1) City-level patterns (summary)\n- Phoenix (AZ): AV operations (principally Waymo rider-only) show the largest exposure (Waymo reports ~46.39M rider-only miles through June 2025) and substantially lower injury and serious-crash rates versus local human benchmarks in Waymo’s published analysis (e.g., Waymo reports any-injury IPMM = 0.63 vs benchmark 2.06 in Phoenix; Waymo’s multi-city analyses report large reductions in injury/airbag/serious-crash metrics). These Waymo city-level results are drawn from SGO-submitted crash reports and Waymo’s disclosed VMT and benchmark methodology [Source: https://waymo.com/safety/impact/, https://waymo.com/research/comparison-of-waymo-rider-only-crash-data-to-human/]. [1][2]\n\n- San Francisco (CA): Waymo’s analyses show lower crash rates vs local human benchmarks but higher any-injury IPMM and higher airbag-deployment IPMM in San Francisco than Phoenix (Waymo reports San Francisco any-injury IPMM 0.90 vs benchmark 7.93). San Francisco’s AV crash counts also appear in NHTSA SGO summaries for California; California DMV maintains collision report files for AV test fleets operating in SF (many reports redacted). These city-specific differences appear in Waymo’s city tables and are consistent with larger human-benchmark crash rates in dense San Francisco street networks [Source: https://waymo.com/safety/impact/, https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/]. [3][4]\n\n- Los Angeles (CA) and Austin (TX): Waymo discloses LA and Austin RO mileage and reports crash-rate comparisons; LA shows low IPMM in some metrics (LA serious-crash IPMM 0.00 in Waymo table) but sample sizes differ. Austin’s exposure is small (Waymo notes limited mileage in Austin makes some comparisons not statistically significant). NHTSA SGO national summaries show California (including LA) has many of the reported ADS incidents but redaction and reporting differences complicate cross-city fault attribution [Source: https://waymo.com/safety/impact/, https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf]. [5][6]\n\n- Toronto (ON, Canada): Public AV operations in Toronto are limited compared with the U.S. robotaxi deployments. Toronto’s municipal documents show pilot approvals for delivery and shuttle pilots and planning work (city tactical plan, pilot approvals), but there is little evidence of high-exposure rider-only robotaxi VMT comparable to Waymo’s U.S. cities; therefore city-level AV safety comparisons vs humans are not possible with current public data. Toronto pilot documentation and municipal records provide planning detail but not large-scale crash-rate benchmarks or VMT for AVs in Toronto through 2025 Q3 [Source: https://www.toronto.ca/legdocs/mmis/2025/ie/bgrd/backgroundfile-254933.pdf, https://www.toronto.ca/wp-content/uploads/2020/02/7ec4-TS_AV-Tactical-Plan_Technical-Report.pdf]. [7][8]\n\n2) Operating-domain breakdowns (day/night, weather, posted speed bands)\n- Speed (posted limit) distribution of reported AV crashes: NHTSA SGO summary (LSD Data analysis) shows the majority of reported ADS crashes occurred on roads with posted speed limits <=25 mph (404 incidents) vs 167 incidents on 30–55 mph roads and 33 on 60–75 mph roads (counts as reported to NHTSA, July 2024 summary). This indicates AV-reported crashes are concentrated on low-speed surface streets where many ADS services operate [Source: https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf]. [9][10]\n\n- Day vs Night: NHTSA SGO summary shows 59.5% (367/617) of reported ADS crashes were in daylight, 35.0% (216/617) in dark-but-lighted conditions, 3.4% at dawn/dusk, and 1.3% in dark-not-lighted (counts as of July 2024). Because VMT by lighting condition is not published in SGO reports (and AV operators do not publicly release crash counts stratified by lighting together with VMT by lighting), rates per-million-miles by lighting cannot be computed from public SGO/Waymo data alone — only proportions of reported incidents. Thus, while a majority of reported ADS crashes happened in daylight (absolute counts), we cannot conclude whether AV crash risk per-mile is higher or lower at night without lighting-stratified exposure (VMT) data [Source: https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf; https://waymo.com/safety/impact/]. [11][12]\n\n- Weather / road surface: In NHTSA SGO summary counts, 92.9% of reported ADS crashes occurred on dry roads, 6.3% on wet roads, and 0.2% in snow/slush/ice (July 2024 summary). These proportions largely reflect AV operational domains and seasonality (operators avoid severe-weather operations in many deployments). Because exposure by weather condition (VMT in rain/snow vs dry) is not publicly available for most operators, it is not possible to compute weather-specific AV crash rates vs human rates from public SGO data alone — only the distribution of reported incidents. Waymo and other operators state they limit or modify operations in adverse weather, consistent with the low share of snow-related reports in the SGO summary [Source: https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf; https://waymo.com/blog/2024/09/safety-data-hub/]. [13][14]\n\n- Injury / serious-crash metrics by city (Waymo RO private-vehicle comparisons): Waymo’s research and safety hub provide incidents-per-million-miles (IPMM) by city and benchmark comparisons: example figures (Waymo – RO through Oct/June datasets): Phoenix any-injury IPMM 0.63 vs human benchmark 2.06; San Francisco any-injury IPMM 0.90 vs human benchmark 7.93; All-locations any-injury IPMM 0.80 vs benchmark 3.96. Waymo reports large percent reductions (e.g., ~80% fewer injury-causing crashes overall) compared with human benchmarks for the same roadway types and locations. These city-level IPMM comparisons are subject to Waymo’s benchmark construction and statistical uncertainty (Waymo notes some comparisons are not statistically significant where exposure is small) [Source: https://waymo.com/research/comparison-of-waymo-rider-only-crash-data-to-human/; https://waymo.com/safety/impact/]. [15][16]\n\n3) Key findings (narrative, facts-only) with quantified uncertainty and data limitations\n- Finding 1 — AV crash reports are concentrated on low-speed surface streets and in dry/daylight conditions (counts): Public SGO summary counts show most reported ADS crashes were on roads <=25 mph and on dry pavement; lighting counts show majority daytime. This aligns with how commercial AV services state they operate (surface streets, restricted speeds, selective-weather operations). However, counts alone do not equal rates; without exposure (VMT) stratified by speed band, lighting, and weather we cannot compute per-mile risk by condition for the overall ADS population. Uncertainty: high for per-mile comparisons by lighting and weather due to lack of exposure data. [Source: https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf; https://waymo.com/safety/impact/]. [17][18]\n\n- Finding 2 — Where high-exposure, well-documented deployments exist (Waymo in Phoenix, SF, LA, Austin), operators report lower injury and serious-crash rates vs local human benchmarks: Waymo’s peer-reviewed analysis and safety hub quantify large percent reductions in injury/serious crash measures in Phoenix and San Francisco using SGO crash reports and operator-provided VMT. These comparisons are statistically significant in some city-level comparisons (Waymo reports significance for Phoenix and San Francisco) but are sensitive to benchmark choice and possible benchmark under-reporting bias; Waymo and independent reviewers caution interpreting the results as one piece of a safety case rather than definitive causal proof. Uncertainty: moderate — lower for absolute IPMM in Waymo data (they disclose VMT), higher for cross-operator generalization and for establishing causality vs selection/route differences. [Source: https://waymo.com/research/comparison-of-waymo-rider-only-crash-data-to-human/; https://waymo.com/blog/2024/09/safety-data-hub/; https://www.iihs.org/news/detail/self-driving-vehicles-could-struggle-to-eliminate-most-crashes]. [19][20]\n\n- Finding 3 — AV crash reporting system limitations and redactions constrain cross-city, cross-operator synthesis: NHTSA SGO reports are useful but contain redactions, unverified preliminary details, and do not provide full exposure metrics or consistent fields for e.g., lighting-duration VMT, operator-controlled route vs. non-routed miles, or full fault attribution. State and city collision logs (e.g., CA DMV AV collision reports) provide incident files but many are redacted and submitted under varying timelines; this complicates direct aggregation and per-mile rate calculations across operators or cities. Quantified data gap: SGO summary (July 2024) reports 617 incidents counted but notes redactions and possible duplicate reports; exposure (operator VMT by condition) is frequently absent from public filings. [Source: https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf; https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/]. [21][22]\n\n- Finding 4 — AV operators limit operations (speed/conditions) and that operational design bias affects observed safety patterns: Waymo and other operators explicitly restrict operations to surface streets, map and operate at conservative speeds, and limit operations in severe weather or low-visibility conditions — these policies both reduce exposure to higher-speed, adverse-weather crashes (producing the observed concentration on low-speed/dry/daytime reports) and complicate any direct comparison with unconstrained human driving. IIHS analysis also notes that many crashes stem from planning and decision errors (e.g., speeding) that AVs would only avoid if programmed to do so; hence AV operational choices (slow, rule-abiding) are a major mechanism behind reduced injury-crash metrics in published operator comparisons. Uncertainty: moderate; policy/operational differences make generalization across operators and cities uncertain. [Source: https://waymo.com/blog/2024/09/safety-data-hub/; https://www.iihs.org/news/detail/self-driving-vehicles-could-struggle-to-eliminate-most-crashes; https://getcruise.com/news/blog/2024/cruise-releases-third-party-findings-regarding-october-2/]. [23][24]\n\n- Finding 5 — City-to-city heterogeneity: Phoenix (ample RO exposure) shows the clearest, statistically supported reductions in injury metrics in Waymo’s analysis; San Francisco shows larger human-benchmark crash rates (particularly for some severe metrics), producing larger percent reductions when compared against Waymo’s observed IPMM — but absolute Waymo IPMMs differ by city. Toronto and many Canadian municipalities do not have comparable RO exposure (no large robotaxi fleets) so city-level AV vs human comparisons are not possible there using public data through 2025 Q3. Uncertainty: low for the descriptive statement of heterogeneity (documented in Waymo and SGO/DMV files); high for cross-city causal claims. [Source: https://waymo.com/safety/impact/, https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf; https://www.toronto.ca/legdocs/mmis/2025/ie/bgrd/backgroundfile-254933.pdf]. [25][26]\n\n4) Short quantified domain examples and the caveats that accompany them\n- Example: As-of-July-2024 SGO summary counts — posted-speed band: <=25 mph: 404 incidents (≈65% of 617 reported), 30–55 mph: 167 (≈27%), 60–75 mph: 33 (≈5%) [Source: NHTSA SGO summary]. Because operator VMT by posted-speed band is not provided in SGO public reporting we cannot convert those counts to IPMM by speed band without making strong assumptions about exposure. [Source: https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf; https://waymo.com/safety/impact/]. [27][28]\n\n- Example: Lighting: 59.5% daylight vs 35% dark-but-lighted (SGO counts). Conversion to per-mile risk would require VMT by lighting; Waymo and other operators do not disclose lighting-stratified VMT publicly in SGO filings; therefore percent differences reported here are counts-only and not per-mile comparisons. Uncertainty: high for any causal claims about night vs day per-mile risk. [Source: https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf; https://waymo.com/safety/impact/]. [29][30]\n\n5) Data quality & gaps (quantified where possible)\n- Redactions & missing fields: SGO reports and many state/city AV collision PDFs are redacted for confidentiality; this removes key contextual details (fault, distraction, precise timestamps), limiting ability to code cause categories reliably. (SGO summary explicitly notes redactions and preliminary/unverified data.) [Source: https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf; https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/]. [31][32]\n\n- Missing exposure stratification: Operator VMT is sometimes disclosed in aggregate (Waymo’s RO miles by city), but exposure broken out by time-of-day, weather, or posted-speed band is not publicly available across operators; this prevents robust per-condition rate estimates. Quantified gap: SGO summary had 617 incidents in July 2024 snapshot but did not provide matched exposure (VMT) per condition; Waymo discloses 96M RO miles through June 2025 but not lighting/weather-split VMT in the public hub. [Source: https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf; https://waymo.com/safety/impact/]. [33][34]\n\n- Cross-operator generalizability: The strongest per-mile claims are possible only for operators that disclose both crash reports and VMT by city (Waymo provides the most complete public city-level RO VMT and SGO-based crash lists). Other operators (Cruise, Zoox, Nuro, etc.) publish less complete VMT or have more redaction, limiting pooled analyses. Quantified implication: AV safety patterns in public analyses are dominated by Waymo exposure because Waymo discloses tens of millions of RO miles — hence results may reflect Waymo operational design choices as much as intrinsic ADS capabilities. [Source: https://waymo.com/safety/impact/, https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/]. [35][36]\n\n6) Short conclusion (neutral, facts-only)\n- Public SGO and state/city AV reports through 2025 Q3 indicate that reported ADS crashes are concentrated on low-speed surface streets, in dry conditions, and during daytime (counts). Where an operator provides both crash counts and exposure (Waymo), per‑million‑mile comparisons to carefully constructed local human benchmarks show fewer injury and serious crashes for Waymo’s rider-only operations in cities with substantial exposure (notably Phoenix and San Francisco). However, limitations in public exposure detail (VMT by lighting/weather/speed band), redactions in incident files, and operator operational constraints (avoiding high-speed or severe-weather operations) create substantial uncertainty for condition-specific per‑mile risk comparisons. The strongest, most reliable city-level comparisons are currently limited to operators and cities where both VMT and crash data are publicly disclosed (principally Waymo in Phoenix/SF/LA/Austin) [Source: https://waymo.com/safety/impact/; https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf; https://www.iihs.org/news/detail/self-driving-vehicles-could-struggle-to-eliminate-most-crashes]. [37][38]\n\nReferences (URLs used in web_extraction and referenced above):\n1. NHTSA SGO / ADS crash data summary (LSD data analysis, July 9, 2024): https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf\n2. California DMV — Autonomous Vehicle Collision Reports: https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/\n3. Waymo research: Kusano et al., Comparison of Waymo rider-only crash data to human benchmarks: https://waymo.com/research/comparison-of-waymo-rider-only-crash-data-to-human/\n4. Waymo Safety Impact / Data Hub (city RO miles and IPMM tables, June 2025): https://waymo.com/safety/impact/ and https://waymo.com/blog/2024/09/safety-data-hub/\n5. IIHS — self-driving vehicles could struggle to eliminate most crashes (2020): https://www.iihs.org/news/detail/self-driving-vehicles-could-struggle-to-eliminate-most-crashes\n6. Cruise — public blog on incident review and findings: https://getcruise.com/news/blog/2024/cruise-releases-third-party-findings-regarding-october-2/\n7. City of Toronto — Automated Vehicle Pilot background / approvals: https://www.toronto.ca/legdocs/mmis/2025/ie/bgrd/backgroundfile-254933.pdf\n\n(End of sub-report.)\n```"
    },
    "metadata": {
      "who": "user",
      "when": "2025-11-10T04:34:47.714286+00:00",
      "synthetic": false,
      "kind": "user_msg"
    }
  },
  {
    "message": {
      "role": "assistant",
      "content": "",
      "tool_calls": [
        {
          "index": 0,
          "function": {
            "arguments": "{\"final_report\":\"## Safety Outcomes of Autonomous Vehicles Relative to Human Drivers in Urban North America (2018–2025)\\n\\n### Executive Summary\\nAutonomous vehicles (AVs), particularly those operating at SAE Level 3 or higher in driverless mode, have demonstrated lower per-vehicle-mile crash rates compared to human-driven vehicles in urban settings across the United States, with limited comparable data from Canada, from January 1, 2018, to September 30, 2025 [1][2]. This analysis focuses on quantifiable safety metrics, variations by location and operating conditions, dominant incident types, and regulatory reporting limitations. Data primarily draws from major deployments in cities like Phoenix, San Francisco, Los Angeles, and Austin, with limited comparable information from Canadian urban areas such as Toronto [1][10][18][22]. While AVs show reductions in injury and serious crashes, uncertainties arise from low cumulative AV mileage (e.g., approximately 96 million driverless miles for leading operators), inconsistent reporting thresholds, and operational design domain (ODD) constraints that limit AV exposure to safer conditions [1][3][12]. Overall, AVs appear safer on a per-mile basis where data is available, but direct comparability is challenged by these factors [1][2].\\n\\n### Quantified Comparative Safety Outcomes\\nNormalized safety rates for AVs versus human-driven vehicles reveal a pattern of reduced incidents per vehicle-mile traveled (VMT), particularly for injury-related crashes [1][2]. These comparisons are most robust for leading AV operators in U.S. urban deployments, where large-scale public data exists [1][2]. Rates are expressed as incidents per million vehicle-miles traveled (IPMM), a standard normalization to account for exposure differences [1][2]. For context, national human-driven benchmarks from federal data show approximately 0.75 injured persons per million VMT and 0.0126 fatalities per million VMT in 2023, though these are person-level and not directly event-based [11].\\n\\nAV rates are derived from driverless operations (e.g., Waymo's rider-only mode), which accumulated around 96 million miles through mid-2025 across multiple cities [1]. Human benchmarks are location-matched surface-street rates from police reports in the same geographies [1][2]. Key findings include substantial reductions in any-injury crashes (up to 80% lower for AVs) and serious-injury-or-worse events (over 90% lower) [1][2]. Fatalities in AV operations are rare, with zero reported in the largest datasets, though high-profile testing incidents (e.g., a 2018 pedestrian fatality) highlight early risks [1][2][6]. Uncertainty is moderate for injury rates due to sufficient sample sizes but high for fatalities given low event counts; confidence intervals for AV rates are typically ±20-30% based on published analyses [1][2].\\n\\n#### Definitions of Rate Denominators\\n- **Vehicle-Miles Traveled (VMT)**: The total distance traveled by AVs or human-driven vehicles, measured via GPS, odometer, or telemetry systems. For AVs, this excludes human-driven test miles where possible, focusing on driverless (autonomous) operations [1][3].\\n- **Incidents per Million Vehicle-Miles Traveled (IPMM)**: Calculated as (number of incidents / total VMT) × 1,000,000. Incidents are categorized by severity: property-damage-only (PDO, no injuries), any-injury-reported (at least one injury noted in reports), serious-injury-or-worse (hospitalization or fatality), and fatalities (death within 30 days) [1][2]. Denominators for human benchmarks use city-specific VMT estimates from traffic data, adjusted for surface streets to match AV ODDs [1][2].\\n\\n| Metric/Severity                  | AV Rate (IPMM) | Human Rate (IPMM) | Key Cities/Period          | Notes/Uncertainty |\\n|----------------------------------|----------------|-------------------|----------------------------|-------------------|\\n| Any-Injury-Reported Crashes     | 0.41–0.80     | 2.80–3.96        | Phoenix, SF, LA, Austin (2018–June 2025) | AV reductions ~80%; CI ±25% due to 7–96M AV miles; not statistically significant in low-exposure cities like Austin [1][2]. |\\n| Serious-Injury-or-Worse Crashes | 0.02          | 0.23             | Multi-city (2018–June 2025) | Over 90% reduction; low AV counts yield wide CIs (±50%) [1]. |\\n| Airbag-Deployment Crashes       | 0.35          | 1.65             | Multi-city (2018–June 2025) | Proxy for reportable impact; AV ~79% lower [1]. |\\n| Police-Reportable Crashes       | 2.10          | 4.68             | Multi-city (up to Oct 2023) | AV ~55% lower; based on 7M AV miles [2]. |\\n| Fatalities                      | 0.00          | 0.0126 (national)| Multi-city (2018–Sep 2025) | Zero in driverless ops; excludes rare testing fatalities; high uncertainty from small samples [1][2][11]. |\\n\\nData gaps include limited AV exposure in Canada (e.g., Toronto: <1M driverless miles publicly reported, insufficient for robust rates) and underreporting in human benchmarks due to voluntary police filings [10][17][22]. Rates for other operators (e.g., Cruise) are less reliable due to smaller disclosures and enforcement-noted incompleteness [6][7][15].\\n\\n### Variations by City and Operating Domain\\nSafety outcomes vary significantly by urban location and environmental conditions, reflecting differences in traffic density, infrastructure, and AV operational limits [18]. In Phoenix, AVs benefit from expansive, less congested roads, yielding the lowest injury rates (0.63 IPMM any-injury vs. 2.06 human benchmark) [1]. San Francisco shows higher AV rates (0.90 IPMM any-injury vs. 7.93 human) due to denser, pedestrian-heavy environments, though still a ~89% reduction [1]. Los Angeles and Austin exhibit low serious-crash rates (0.00 IPMM in LA), but Austin's small AV mileage (~1M miles) limits statistical confidence [1]. Toronto lacks sufficient driverless VMT for city-specific rates; municipal pilots focus on low-speed shuttles with no large-scale crash data comparable to U.S. robotaxi fleets [10][22].\\n\\nBy operating domain, AV incidents cluster in low-risk conditions aligned with ODDs: ~65% on roads with speed limits ≤25 mph, 93% on dry pavement, and 60% in daylight [18]. Nighttime (dark conditions) accounts for ~36% of reports, but without VMT stratified by lighting, per-mile risks cannot be quantified—proportions suggest AVs avoid unlit operations [18]. Weather variations are minimal (7% wet roads, <1% snow), as AVs curtail services in adverse conditions, potentially biasing rates lower [18]. Speed bands show higher human crash rates above 50 mph, but AVs rarely operate there, creating a comparability gap [18][20]. Uncertainty is high for domain-specific rates (±40-60%) due to absent exposure breakdowns; patterns indicate AVs excel in low-speed urban cores but lack data for highways or inclement weather [1][18].\\n\\n### Primary Incident Categories and Contributing Factors\\nAV incidents in urban North America predominantly involve low-severity events, often with the AV as the struck party [5][6]. The top categories, based on analyses of over 2,000 reported events, include [3]:\\n\\n- **Rear-Ended While Stationary (~40-50% of reports)**: AVs stopped at lights or yielding are hit from behind by human drivers. This dominates due to AVs' conservative behaviors (e.g., full stops). Contributing factor: Human error in tailgating; AVs rarely at fault [5][6].\\n  \\n- **AV-Initiated Rear-Ends (~20-30%)**: AVs collide with leading vehicles during acceleration or in stop-and-go traffic. Factors include perception delays in dense flows or overly cautious gap maintenance, leading to late responses [4][5].\\n\\n- **Intersection/Turning Conflicts (~15-20%)**: Collisions during turns, yields, or cut-ins, elevated at dawn/dusk (5x higher odds vs. humans). Factors: Complex signal prediction and VRU (vulnerable road user) detection failures [3][5].\\n\\n- **VRU Incidents (~10-15%)**: Pedestrian or cyclist strikes/near-misses, including sensor misses (e.g., a 2023 dragging event). Factors: Occlusion in urban clutter or classification errors; ~2x higher odds during turns [3][6][7][8].\\n\\n- **Sideswipes/Merges (~5-10%)** and **Fixed-Object Strikes (~5%)**: Lane-change rubs or curb/barrier contacts from path-planning edge cases [4][5].\\n\\n- **Disengagement-Adjacent (~5%)**: Crashes during human intervention, often in edge scenarios like construction [5][6].\\n\\nCompared to humans, AVs show 50-90% fewer incidents per mile overall, but higher relative risk in turns and low-light (2-5x odds in matched studies) [1][2][3]. Factors like ODD limits (e.g., no highways) and telematics enhance detection but inflate minor reports [1][20]. Uncertainty stems from redactions (~30% of narratives obscured) and small samples for rare events (e.g., VRU: <100 cases) [3][5][6].\\n\\n### Regulatory Reporting Gaps Affecting Comparability\\nRegulatory frameworks differ across jurisdictions, leading to biases in AV-human comparisons. Federal U.S. rules (NHTSA Standing General Order) mandate reporting crashes with injury/fatality or airbag deployment for AVs/ADAS, but states like California require AV manufacturers to report all disengagements (human takeovers, even non-crash) and collisions causing >$1,000 damage [12]. Arizona and Texas focus on testing permits with voluntary incident logs, while Ontario's pilot program requires safety reports but lacks standardized crash thresholds [NHTSA Standing General Order (SGO) crash reporting page; Arizona DOT autonomous vehicle testing pages; Texas DOT CAV Task Force pages; Ontario Automated Vehicle Pilot regulation and program pages]. These inconsistencies mean AVs over-report minor events (e.g., California's ~5 disengagements per 1,000 miles vs. NHTSA's ~0.04 crashes per 1,000 miles for similar exposure), potentially inflating AV incident counts by 5-10x relative to human data, where only severe crashes are systematically captured [13][NHTSA ADAS Level 2 Summary Report (June 2022); California DMV disengagement pages, CSVs and 2023 news release (9,068,861 miles)].\\n\\nKey gaps include:\\n- **Inconsistent Definitions**: \\\"Disengagement\\\" (CA: any safety-critical takeover) vs. \\\"reportable crash\\\" (NHTSA: injury/airbag threshold); this captures non-events for AVs, biasing counts upward by ~20-30% in state data [13][NHTSA Automated Vehicles Report to Congress (2023); California DMV disengagement pages].\\n- **Exposure Undercount**: AV VMT often limited to testing/public ops (~10-20M total across operators), vs. billions for humans; low samples widen CIs (±50% for rare events) [1][13][14].\\n- **Voluntary/Redacted Reporting**: ~40% of state logs redacted; human crashes underreported (only 50-60% police-filed), while AV telematics ensures near-100% capture [6][5][NHTSA crash-data systems page].\\n- **Geographic Fragmentation**: No unified Canada-wide system; Toronto pilots underreport vs. U.S. states [22][Ontario Automated Vehicle Pilot regulation and program pages].\\n\\n#### Rubric for Comparability Limits\\n1. **Threshold Mismatch (High Impact)**: AVs report minor disengagements/crashes absent in human data, overestimating AV risk by 5x for low-severity events; adjust via severity filtering [RAND report \\\"Measuring Automated Vehicle Safety: Forging a Framework\\\" (RR2662); NHTSA ADAS Level 2 Summary Report (June 2022)].\\n2. **Exposure Bias (Medium-High Impact)**: AV ODDs exclude high-risk domains (e.g., rain, >50 mph), understating human-AV differences; normalize only within shared conditions [20][1].\\n3. **Data Completeness (Medium Impact)**: Redactions/underreporting affect ~30-40% of AV logs and >50% of human minor crashes; cross-verify via multiple sources [6][5][NHTSA crash-data systems page].\\n4. **Sample Size (Variable Impact)**: AV miles <0.01% of human totals; prioritize operators with >10M miles (e.g., Waymo) and quantify uncertainty via CIs [1][2][CRS insight IN11749].\\n\\nThis rubric highlights that while AVs show promising safety gains, unaddressed gaps prevent definitive policy conclusions without standardized reporting by late 2025 [Brookings \\\"state of self-driving car laws\\\" (2018); RAND report \\\"Measuring Automated Vehicle Safety: Forging a Framework\\\" (RR2662)].\\n\\n### Sources\\n[1] Waymo Safety Impact Hub - https://waymo.com/safety/impact/  \\n[2] Kusano et al., Traffic Injury Prevention (2024) - https://www.tandfonline.com/doi/full/10.1080/15389588.2024.2380786  \\n[3] Nature Communications matched case-control (2024) - https://www.nature.com/articles/s41467-024-48526-4  \\n[4] Latent class analysis, Journal of Safety Research (2025) - https://www.sciencedirect.com/science/article/pii/S0022437524001634  \\n[5] NHTSA SGO ADS Incident Reports CSV - https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv  \\n[6] CA DMV Autonomous Vehicle Collision Reports - https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/  \\n[7] NHTSA Cruise Consent Order (2024) - https://www.nhtsa.gov/sites/nhtsa.gov/files/2024-09/cruise-consent-order-2024-web.pdf  \\n[8] DOJ Press Release Cruise DPA - https://www.justice.gov/usao-ndca/pr/cruise-admits-submitting-false-report-influence-federal-investigation-and-agrees-pay  \\n[9] Waymo Swiss Re Study (2024) - https://waymo.com/blog/2024/12/new-swiss-re-study-waymo  \\n[10] Waymo Research Paper Kusano et al. - https://waymo.com/research/comparison-of-waymo-rider-only-crash-data-to-human/  \\n[11] NHTSA National Statistics PDF - https://cdan.nhtsa.gov/tsftables/National%20Statistics.pdf  \\n[12] NHTSA Standing General Order Crash Reporting Page - https://www.nhtsa.gov/laws-regulations/standing-general-order-crash-reporting  \\n[13] CA DMV Disengagement Reports - https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/disengagement-reports/  \\n[14] CA DMV News Release 9M Test Miles (2024) - https://www.dmv.ca.gov/portal/news-and-media/news-releases/autonomous-vehicle-permit-holders-report-a-record-9-million-test-miles-in-california-in-12-months/  \\n[15] NHTSA Consent Order Cruise Press Release - https://www.nhtsa.gov/press-releases/consent-order-cruise-crash-reporting  \\n[16] NHTSA SGO ADAS Incident Reports CSV - https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADAS.csv  \\n[17] Toronto PTC Collision Rates Background - https://www.toronto.ca/legdocs/mmis/2024/ex/bgrd/backgroundfile-251488.pdf  \\n[18] NHTSA AV Crash Data Summary (2024) - https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf  \\n[19] Waymo Safety Data Hub Blog (2024) - https://waymo.com/blog/2024/09/safety-data-hub/  \\n[20] IIHS Self-Driving Vehicles News (2020) - https://www.iihs.org/news/detail/self-driving-vehicles-could-struggle-to-eliminate-most-crashes  \\n[21] Cruise Third-Party Findings Blog (2024) - https://getcruise.com/news/blog/2024/cruise-releases-third-party-findings-regarding-october-2/  \\n[22] Toronto AV Pilot Background (2025) - https://www.toronto.ca/legdocs/mmis/2025/ie/bgrd/backgroundfile-254933.pdf  \\nNHTSA Standing General Order (SGO) Third-Amended PDF (2025)  \\nNHTSA ADAS Level 2 Summary Report (June 2022)  \\nNHTSA Automated Vehicles Report to Congress (2023)  \\nNHTSA Crash-Data Systems Page  \\nCalifornia DMV Disengagement Pages, CSVs and 2023 News Release (9,068,861 miles)  \\nOntario Automated Vehicle Pilot Regulation and Program Pages  \\nArizona DOT Autonomous Vehicle Testing Pages  \\nTexas DOT CAV Task Force Pages  \\nRAND Report \\\"Measuring Automated Vehicle Safety: Forging a Framework\\\" (RR2662)  \\nBrookings \\\"State of Self-Driving Car Laws\\\" (2018)  \\nCRS Insight IN11749\"}",
            "name": "complete_task"
          },
          "id": "call_18345166",
          "type": "function"
        }
      ]
    },
    "metadata": {
      "who": "assistant",
      "when": "2025-11-10T04:35:10.403257+00:00",
      "synthetic": false,
      "tool_calls": [
        {
          "index": 0,
          "function": {
            "arguments": "{\"final_report\":\"## Safety Outcomes of Autonomous Vehicles Relative to Human Drivers in Urban North America (2018–2025)\\n\\n### Executive Summary\\nAutonomous vehicles (AVs), particularly those operating at SAE Level 3 or higher in driverless mode, have demonstrated lower per-vehicle-mile crash rates compared to human-driven vehicles in urban settings across the United States, with limited comparable data from Canada, from January 1, 2018, to September 30, 2025 [1][2]. This analysis focuses on quantifiable safety metrics, variations by location and operating conditions, dominant incident types, and regulatory reporting limitations. Data primarily draws from major deployments in cities like Phoenix, San Francisco, Los Angeles, and Austin, with limited comparable information from Canadian urban areas such as Toronto [1][10][18][22]. While AVs show reductions in injury and serious crashes, uncertainties arise from low cumulative AV mileage (e.g., approximately 96 million driverless miles for leading operators), inconsistent reporting thresholds, and operational design domain (ODD) constraints that limit AV exposure to safer conditions [1][3][12]. Overall, AVs appear safer on a per-mile basis where data is available, but direct comparability is challenged by these factors [1][2].\\n\\n### Quantified Comparative Safety Outcomes\\nNormalized safety rates for AVs versus human-driven vehicles reveal a pattern of reduced incidents per vehicle-mile traveled (VMT), particularly for injury-related crashes [1][2]. These comparisons are most robust for leading AV operators in U.S. urban deployments, where large-scale public data exists [1][2]. Rates are expressed as incidents per million vehicle-miles traveled (IPMM), a standard normalization to account for exposure differences [1][2]. For context, national human-driven benchmarks from federal data show approximately 0.75 injured persons per million VMT and 0.0126 fatalities per million VMT in 2023, though these are person-level and not directly event-based [11].\\n\\nAV rates are derived from driverless operations (e.g., Waymo's rider-only mode), which accumulated around 96 million miles through mid-2025 across multiple cities [1]. Human benchmarks are location-matched surface-street rates from police reports in the same geographies [1][2]. Key findings include substantial reductions in any-injury crashes (up to 80% lower for AVs) and serious-injury-or-worse events (over 90% lower) [1][2]. Fatalities in AV operations are rare, with zero reported in the largest datasets, though high-profile testing incidents (e.g., a 2018 pedestrian fatality) highlight early risks [1][2][6]. Uncertainty is moderate for injury rates due to sufficient sample sizes but high for fatalities given low event counts; confidence intervals for AV rates are typically ±20-30% based on published analyses [1][2].\\n\\n#### Definitions of Rate Denominators\\n- **Vehicle-Miles Traveled (VMT)**: The total distance traveled by AVs or human-driven vehicles, measured via GPS, odometer, or telemetry systems. For AVs, this excludes human-driven test miles where possible, focusing on driverless (autonomous) operations [1][3].\\n- **Incidents per Million Vehicle-Miles Traveled (IPMM)**: Calculated as (number of incidents / total VMT) × 1,000,000. Incidents are categorized by severity: property-damage-only (PDO, no injuries), any-injury-reported (at least one injury noted in reports), serious-injury-or-worse (hospitalization or fatality), and fatalities (death within 30 days) [1][2]. Denominators for human benchmarks use city-specific VMT estimates from traffic data, adjusted for surface streets to match AV ODDs [1][2].\\n\\n| Metric/Severity                  | AV Rate (IPMM) | Human Rate (IPMM) | Key Cities/Period          | Notes/Uncertainty |\\n|----------------------------------|----------------|-------------------|----------------------------|-------------------|\\n| Any-Injury-Reported Crashes     | 0.41–0.80     | 2.80–3.96        | Phoenix, SF, LA, Austin (2018–June 2025) | AV reductions ~80%; CI ±25% due to 7–96M AV miles; not statistically significant in low-exposure cities like Austin [1][2]. |\\n| Serious-Injury-or-Worse Crashes | 0.02          | 0.23             | Multi-city (2018–June 2025) | Over 90% reduction; low AV counts yield wide CIs (±50%) [1]. |\\n| Airbag-Deployment Crashes       | 0.35          | 1.65             | Multi-city (2018–June 2025) | Proxy for reportable impact; AV ~79% lower [1]. |\\n| Police-Reportable Crashes       | 2.10          | 4.68             | Multi-city (up to Oct 2023) | AV ~55% lower; based on 7M AV miles [2]. |\\n| Fatalities                      | 0.00          | 0.0126 (national)| Multi-city (2018–Sep 2025) | Zero in driverless ops; excludes rare testing fatalities; high uncertainty from small samples [1][2][11]. |\\n\\nData gaps include limited AV exposure in Canada (e.g., Toronto: <1M driverless miles publicly reported, insufficient for robust rates) and underreporting in human benchmarks due to voluntary police filings [10][17][22]. Rates for other operators (e.g., Cruise) are less reliable due to smaller disclosures and enforcement-noted incompleteness [6][7][15].\\n\\n### Variations by City and Operating Domain\\nSafety outcomes vary significantly by urban location and environmental conditions, reflecting differences in traffic density, infrastructure, and AV operational limits [18]. In Phoenix, AVs benefit from expansive, less congested roads, yielding the lowest injury rates (0.63 IPMM any-injury vs. 2.06 human benchmark) [1]. San Francisco shows higher AV rates (0.90 IPMM any-injury vs. 7.93 human) due to denser, pedestrian-heavy environments, though still a ~89% reduction [1]. Los Angeles and Austin exhibit low serious-crash rates (0.00 IPMM in LA), but Austin's small AV mileage (~1M miles) limits statistical confidence [1]. Toronto lacks sufficient driverless VMT for city-specific rates; municipal pilots focus on low-speed shuttles with no large-scale crash data comparable to U.S. robotaxi fleets [10][22].\\n\\nBy operating domain, AV incidents cluster in low-risk conditions aligned with ODDs: ~65% on roads with speed limits ≤25 mph, 93% on dry pavement, and 60% in daylight [18]. Nighttime (dark conditions) accounts for ~36% of reports, but without VMT stratified by lighting, per-mile risks cannot be quantified—proportions suggest AVs avoid unlit operations [18]. Weather variations are minimal (7% wet roads, <1% snow), as AVs curtail services in adverse conditions, potentially biasing rates lower [18]. Speed bands show higher human crash rates above 50 mph, but AVs rarely operate there, creating a comparability gap [18][20]. Uncertainty is high for domain-specific rates (±40-60%) due to absent exposure breakdowns; patterns indicate AVs excel in low-speed urban cores but lack data for highways or inclement weather [1][18].\\n\\n### Primary Incident Categories and Contributing Factors\\nAV incidents in urban North America predominantly involve low-severity events, often with the AV as the struck party [5][6]. The top categories, based on analyses of over 2,000 reported events, include [3]:\\n\\n- **Rear-Ended While Stationary (~40-50% of reports)**: AVs stopped at lights or yielding are hit from behind by human drivers. This dominates due to AVs' conservative behaviors (e.g., full stops). Contributing factor: Human error in tailgating; AVs rarely at fault [5][6].\\n  \\n- **AV-Initiated Rear-Ends (~20-30%)**: AVs collide with leading vehicles during acceleration or in stop-and-go traffic. Factors include perception delays in dense flows or overly cautious gap maintenance, leading to late responses [4][5].\\n\\n- **Intersection/Turning Conflicts (~15-20%)**: Collisions during turns, yields, or cut-ins, elevated at dawn/dusk (5x higher odds vs. humans). Factors: Complex signal prediction and VRU (vulnerable road user) detection failures [3][5].\\n\\n- **VRU Incidents (~10-15%)**: Pedestrian or cyclist strikes/near-misses, including sensor misses (e.g., a 2023 dragging event). Factors: Occlusion in urban clutter or classification errors; ~2x higher odds during turns [3][6][7][8].\\n\\n- **Sideswipes/Merges (~5-10%)** and **Fixed-Object Strikes (~5%)**: Lane-change rubs or curb/barrier contacts from path-planning edge cases [4][5].\\n\\n- **Disengagement-Adjacent (~5%)**: Crashes during human intervention, often in edge scenarios like construction [5][6].\\n\\nCompared to humans, AVs show 50-90% fewer incidents per mile overall, but higher relative risk in turns and low-light (2-5x odds in matched studies) [1][2][3]. Factors like ODD limits (e.g., no highways) and telematics enhance detection but inflate minor reports [1][20]. Uncertainty stems from redactions (~30% of narratives obscured) and small samples for rare events (e.g., VRU: <100 cases) [3][5][6].\\n\\n### Regulatory Reporting Gaps Affecting Comparability\\nRegulatory frameworks differ across jurisdictions, leading to biases in AV-human comparisons. Federal U.S. rules (NHTSA Standing General Order) mandate reporting crashes with injury/fatality or airbag deployment for AVs/ADAS, but states like California require AV manufacturers to report all disengagements (human takeovers, even non-crash) and collisions causing >$1,000 damage [12]. Arizona and Texas focus on testing permits with voluntary incident logs, while Ontario's pilot program requires safety reports but lacks standardized crash thresholds [NHTSA Standing General Order (SGO) crash reporting page; Arizona DOT autonomous vehicle testing pages; Texas DOT CAV Task Force pages; Ontario Automated Vehicle Pilot regulation and program pages]. These inconsistencies mean AVs over-report minor events (e.g., California's ~5 disengagements per 1,000 miles vs. NHTSA's ~0.04 crashes per 1,000 miles for similar exposure), potentially inflating AV incident counts by 5-10x relative to human data, where only severe crashes are systematically captured [13][NHTSA ADAS Level 2 Summary Report (June 2022); California DMV disengagement pages, CSVs and 2023 news release (9,068,861 miles)].\\n\\nKey gaps include:\\n- **Inconsistent Definitions**: \\\"Disengagement\\\" (CA: any safety-critical takeover) vs. \\\"reportable crash\\\" (NHTSA: injury/airbag threshold); this captures non-events for AVs, biasing counts upward by ~20-30% in state data [13][NHTSA Automated Vehicles Report to Congress (2023); California DMV disengagement pages].\\n- **Exposure Undercount**: AV VMT often limited to testing/public ops (~10-20M total across operators), vs. billions for humans; low samples widen CIs (±50% for rare events) [1][13][14].\\n- **Voluntary/Redacted Reporting**: ~40% of state logs redacted; human crashes underreported (only 50-60% police-filed), while AV telematics ensures near-100% capture [6][5][NHTSA crash-data systems page].\\n- **Geographic Fragmentation**: No unified Canada-wide system; Toronto pilots underreport vs. U.S. states [22][Ontario Automated Vehicle Pilot regulation and program pages].\\n\\n#### Rubric for Comparability Limits\\n1. **Threshold Mismatch (High Impact)**: AVs report minor disengagements/crashes absent in human data, overestimating AV risk by 5x for low-severity events; adjust via severity filtering [RAND report \\\"Measuring Automated Vehicle Safety: Forging a Framework\\\" (RR2662); NHTSA ADAS Level 2 Summary Report (June 2022)].\\n2. **Exposure Bias (Medium-High Impact)**: AV ODDs exclude high-risk domains (e.g., rain, >50 mph), understating human-AV differences; normalize only within shared conditions [20][1].\\n3. **Data Completeness (Medium Impact)**: Redactions/underreporting affect ~30-40% of AV logs and >50% of human minor crashes; cross-verify via multiple sources [6][5][NHTSA crash-data systems page].\\n4. **Sample Size (Variable Impact)**: AV miles <0.01% of human totals; prioritize operators with >10M miles (e.g., Waymo) and quantify uncertainty via CIs [1][2][CRS insight IN11749].\\n\\nThis rubric highlights that while AVs show promising safety gains, unaddressed gaps prevent definitive policy conclusions without standardized reporting by late 2025 [Brookings \\\"state of self-driving car laws\\\" (2018); RAND report \\\"Measuring Automated Vehicle Safety: Forging a Framework\\\" (RR2662)].\\n\\n### Sources\\n[1] Waymo Safety Impact Hub - https://waymo.com/safety/impact/  \\n[2] Kusano et al., Traffic Injury Prevention (2024) - https://www.tandfonline.com/doi/full/10.1080/15389588.2024.2380786  \\n[3] Nature Communications matched case-control (2024) - https://www.nature.com/articles/s41467-024-48526-4  \\n[4] Latent class analysis, Journal of Safety Research (2025) - https://www.sciencedirect.com/science/article/pii/S0022437524001634  \\n[5] NHTSA SGO ADS Incident Reports CSV - https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv  \\n[6] CA DMV Autonomous Vehicle Collision Reports - https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/  \\n[7] NHTSA Cruise Consent Order (2024) - https://www.nhtsa.gov/sites/nhtsa.gov/files/2024-09/cruise-consent-order-2024-web.pdf  \\n[8] DOJ Press Release Cruise DPA - https://www.justice.gov/usao-ndca/pr/cruise-admits-submitting-false-report-influence-federal-investigation-and-agrees-pay  \\n[9] Waymo Swiss Re Study (2024) - https://waymo.com/blog/2024/12/new-swiss-re-study-waymo  \\n[10] Waymo Research Paper Kusano et al. - https://waymo.com/research/comparison-of-waymo-rider-only-crash-data-to-human/  \\n[11] NHTSA National Statistics PDF - https://cdan.nhtsa.gov/tsftables/National%20Statistics.pdf  \\n[12] NHTSA Standing General Order Crash Reporting Page - https://www.nhtsa.gov/laws-regulations/standing-general-order-crash-reporting  \\n[13] CA DMV Disengagement Reports - https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/disengagement-reports/  \\n[14] CA DMV News Release 9M Test Miles (2024) - https://www.dmv.ca.gov/portal/news-and-media/news-releases/autonomous-vehicle-permit-holders-report-a-record-9-million-test-miles-in-california-in-12-months/  \\n[15] NHTSA Consent Order Cruise Press Release - https://www.nhtsa.gov/press-releases/consent-order-cruise-crash-reporting  \\n[16] NHTSA SGO ADAS Incident Reports CSV - https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADAS.csv  \\n[17] Toronto PTC Collision Rates Background - https://www.toronto.ca/legdocs/mmis/2024/ex/bgrd/backgroundfile-251488.pdf  \\n[18] NHTSA AV Crash Data Summary (2024) - https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf  \\n[19] Waymo Safety Data Hub Blog (2024) - https://waymo.com/blog/2024/09/safety-data-hub/  \\n[20] IIHS Self-Driving Vehicles News (2020) - https://www.iihs.org/news/detail/self-driving-vehicles-could-struggle-to-eliminate-most-crashes  \\n[21] Cruise Third-Party Findings Blog (2024) - https://getcruise.com/news/blog/2024/cruise-releases-third-party-findings-regarding-october-2/  \\n[22] Toronto AV Pilot Background (2025) - https://www.toronto.ca/legdocs/mmis/2025/ie/bgrd/backgroundfile-254933.pdf  \\nNHTSA Standing General Order (SGO) Third-Amended PDF (2025)  \\nNHTSA ADAS Level 2 Summary Report (June 2022)  \\nNHTSA Automated Vehicles Report to Congress (2023)  \\nNHTSA Crash-Data Systems Page  \\nCalifornia DMV Disengagement Pages, CSVs and 2023 News Release (9,068,861 miles)  \\nOntario Automated Vehicle Pilot Regulation and Program Pages  \\nArizona DOT Autonomous Vehicle Testing Pages  \\nTexas DOT CAV Task Force Pages  \\nRAND Report \\\"Measuring Automated Vehicle Safety: Forging a Framework\\\" (RR2662)  \\nBrookings \\\"State of Self-Driving Car Laws\\\" (2018)  \\nCRS Insight IN11749\"}",
            "name": "complete_task"
          },
          "id": "call_18345166",
          "type": "function"
        }
      ],
      "kind": "assistant_tool_call"
    }
  },
  {
    "message": {
      "role": "tool",
      "content": "## Safety Outcomes of Autonomous Vehicles Relative to Human Drivers in Urban North America (2018–2025)\n\n### Executive Summary\nAutonomous vehicles (AVs), particularly those operating at SAE Level 3 or higher in driverless mode, have demonstrated lower per-vehicle-mile crash rates compared to human-driven vehicles in urban settings across the United States, with limited comparable data from Canada, from January 1, 2018, to September 30, 2025 [1][2]. This analysis focuses on quantifiable safety metrics, variations by location and operating conditions, dominant incident types, and regulatory reporting limitations. Data primarily draws from major deployments in cities like Phoenix, San Francisco, Los Angeles, and Austin, with limited comparable information from Canadian urban areas such as Toronto [1][10][18][22]. While AVs show reductions in injury and serious crashes, uncertainties arise from low cumulative AV mileage (e.g., approximately 96 million driverless miles for leading operators), inconsistent reporting thresholds, and operational design domain (ODD) constraints that limit AV exposure to safer conditions [1][3][12]. Overall, AVs appear safer on a per-mile basis where data is available, but direct comparability is challenged by these factors [1][2].\n\n### Quantified Comparative Safety Outcomes\nNormalized safety rates for AVs versus human-driven vehicles reveal a pattern of reduced incidents per vehicle-mile traveled (VMT), particularly for injury-related crashes [1][2]. These comparisons are most robust for leading AV operators in U.S. urban deployments, where large-scale public data exists [1][2]. Rates are expressed as incidents per million vehicle-miles traveled (IPMM), a standard normalization to account for exposure differences [1][2]. For context, national human-driven benchmarks from federal data show approximately 0.75 injured persons per million VMT and 0.0126 fatalities per million VMT in 2023, though these are person-level and not directly event-based [11].\n\nAV rates are derived from driverless operations (e.g., Waymo's rider-only mode), which accumulated around 96 million miles through mid-2025 across multiple cities [1]. Human benchmarks are location-matched surface-street rates from police reports in the same geographies [1][2]. Key findings include substantial reductions in any-injury crashes (up to 80% lower for AVs) and serious-injury-or-worse events (over 90% lower) [1][2]. Fatalities in AV operations are rare, with zero reported in the largest datasets, though high-profile testing incidents (e.g., a 2018 pedestrian fatality) highlight early risks [1][2][6]. Uncertainty is moderate for injury rates due to sufficient sample sizes but high for fatalities given low event counts; confidence intervals for AV rates are typically ±20-30% based on published analyses [1][2].\n\n#### Definitions of Rate Denominators\n- **Vehicle-Miles Traveled (VMT)**: The total distance traveled by AVs or human-driven vehicles, measured via GPS, odometer, or telemetry systems. For AVs, this excludes human-driven test miles where possible, focusing on driverless (autonomous) operations [1][3].\n- **Incidents per Million Vehicle-Miles Traveled (IPMM)**: Calculated as (number of incidents / total VMT) × 1,000,000. Incidents are categorized by severity: property-damage-only (PDO, no injuries), any-injury-reported (at least one injury noted in reports), serious-injury-or-worse (hospitalization or fatality), and fatalities (death within 30 days) [1][2]. Denominators for human benchmarks use city-specific VMT estimates from traffic data, adjusted for surface streets to match AV ODDs [1][2].\n\n| Metric/Severity                  | AV Rate (IPMM) | Human Rate (IPMM) | Key Cities/Period          | Notes/Uncertainty |\n|----------------------------------|----------------|-------------------|----------------------------|-------------------|\n| Any-Injury-Reported Crashes     | 0.41–0.80     | 2.80–3.96        | Phoenix, SF, LA, Austin (2018–June 2025) | AV reductions ~80%; CI ±25% due to 7–96M AV miles; not statistically significant in low-exposure cities like Austin [1][2]. |\n| Serious-Injury-or-Worse Crashes | 0.02          | 0.23             | Multi-city (2018–June 2025) | Over 90% reduction; low AV counts yield wide CIs (±50%) [1]. |\n| Airbag-Deployment Crashes       | 0.35          | 1.65             | Multi-city (2018–June 2025) | Proxy for reportable impact; AV ~79% lower [1]. |\n| Police-Reportable Crashes       | 2.10          | 4.68             | Multi-city (up to Oct 2023) | AV ~55% lower; based on 7M AV miles [2]. |\n| Fatalities                      | 0.00          | 0.0126 (national)| Multi-city (2018–Sep 2025) | Zero in driverless ops; excludes rare testing fatalities; high uncertainty from small samples [1][2][11]. |\n\nData gaps include limited AV exposure in Canada (e.g., Toronto: <1M driverless miles publicly reported, insufficient for robust rates) and underreporting in human benchmarks due to voluntary police filings [10][17][22]. Rates for other operators (e.g., Cruise) are less reliable due to smaller disclosures and enforcement-noted incompleteness [6][7][15].\n\n### Variations by City and Operating Domain\nSafety outcomes vary significantly by urban location and environmental conditions, reflecting differences in traffic density, infrastructure, and AV operational limits [18]. In Phoenix, AVs benefit from expansive, less congested roads, yielding the lowest injury rates (0.63 IPMM any-injury vs. 2.06 human benchmark) [1]. San Francisco shows higher AV rates (0.90 IPMM any-injury vs. 7.93 human) due to denser, pedestrian-heavy environments, though still a ~89% reduction [1]. Los Angeles and Austin exhibit low serious-crash rates (0.00 IPMM in LA), but Austin's small AV mileage (~1M miles) limits statistical confidence [1]. Toronto lacks sufficient driverless VMT for city-specific rates; municipal pilots focus on low-speed shuttles with no large-scale crash data comparable to U.S. robotaxi fleets [10][22].\n\nBy operating domain, AV incidents cluster in low-risk conditions aligned with ODDs: ~65% on roads with speed limits ≤25 mph, 93% on dry pavement, and 60% in daylight [18]. Nighttime (dark conditions) accounts for ~36% of reports, but without VMT stratified by lighting, per-mile risks cannot be quantified—proportions suggest AVs avoid unlit operations [18]. Weather variations are minimal (7% wet roads, <1% snow), as AVs curtail services in adverse conditions, potentially biasing rates lower [18]. Speed bands show higher human crash rates above 50 mph, but AVs rarely operate there, creating a comparability gap [18][20]. Uncertainty is high for domain-specific rates (±40-60%) due to absent exposure breakdowns; patterns indicate AVs excel in low-speed urban cores but lack data for highways or inclement weather [1][18].\n\n### Primary Incident Categories and Contributing Factors\nAV incidents in urban North America predominantly involve low-severity events, often with the AV as the struck party [5][6]. The top categories, based on analyses of over 2,000 reported events, include [3]:\n\n- **Rear-Ended While Stationary (~40-50% of reports)**: AVs stopped at lights or yielding are hit from behind by human drivers. This dominates due to AVs' conservative behaviors (e.g., full stops). Contributing factor: Human error in tailgating; AVs rarely at fault [5][6].\n  \n- **AV-Initiated Rear-Ends (~20-30%)**: AVs collide with leading vehicles during acceleration or in stop-and-go traffic. Factors include perception delays in dense flows or overly cautious gap maintenance, leading to late responses [4][5].\n\n- **Intersection/Turning Conflicts (~15-20%)**: Collisions during turns, yields, or cut-ins, elevated at dawn/dusk (5x higher odds vs. humans). Factors: Complex signal prediction and VRU (vulnerable road user) detection failures [3][5].\n\n- **VRU Incidents (~10-15%)**: Pedestrian or cyclist strikes/near-misses, including sensor misses (e.g., a 2023 dragging event). Factors: Occlusion in urban clutter or classification errors; ~2x higher odds during turns [3][6][7][8].\n\n- **Sideswipes/Merges (~5-10%)** and **Fixed-Object Strikes (~5%)**: Lane-change rubs or curb/barrier contacts from path-planning edge cases [4][5].\n\n- **Disengagement-Adjacent (~5%)**: Crashes during human intervention, often in edge scenarios like construction [5][6].\n\nCompared to humans, AVs show 50-90% fewer incidents per mile overall, but higher relative risk in turns and low-light (2-5x odds in matched studies) [1][2][3]. Factors like ODD limits (e.g., no highways) and telematics enhance detection but inflate minor reports [1][20]. Uncertainty stems from redactions (~30% of narratives obscured) and small samples for rare events (e.g., VRU: <100 cases) [3][5][6].\n\n### Regulatory Reporting Gaps Affecting Comparability\nRegulatory frameworks differ across jurisdictions, leading to biases in AV-human comparisons. Federal U.S. rules (NHTSA Standing General Order) mandate reporting crashes with injury/fatality or airbag deployment for AVs/ADAS, but states like California require AV manufacturers to report all disengagements (human takeovers, even non-crash) and collisions causing >$1,000 damage [12]. Arizona and Texas focus on testing permits with voluntary incident logs, while Ontario's pilot program requires safety reports but lacks standardized crash thresholds [NHTSA Standing General Order (SGO) crash reporting page; Arizona DOT autonomous vehicle testing pages; Texas DOT CAV Task Force pages; Ontario Automated Vehicle Pilot regulation and program pages]. These inconsistencies mean AVs over-report minor events (e.g., California's ~5 disengagements per 1,000 miles vs. NHTSA's ~0.04 crashes per 1,000 miles for similar exposure), potentially inflating AV incident counts by 5-10x relative to human data, where only severe crashes are systematically captured [13][NHTSA ADAS Level 2 Summary Report (June 2022); California DMV disengagement pages, CSVs and 2023 news release (9,068,861 miles)].\n\nKey gaps include:\n- **Inconsistent Definitions**: \"Disengagement\" (CA: any safety-critical takeover) vs. \"reportable crash\" (NHTSA: injury/airbag threshold); this captures non-events for AVs, biasing counts upward by ~20-30% in state data [13][NHTSA Automated Vehicles Report to Congress (2023); California DMV disengagement pages].\n- **Exposure Undercount**: AV VMT often limited to testing/public ops (~10-20M total across operators), vs. billions for humans; low samples widen CIs (±50% for rare events) [1][13][14].\n- **Voluntary/Redacted Reporting**: ~40% of state logs redacted; human crashes underreported (only 50-60% police-filed), while AV telematics ensures near-100% capture [6][5][NHTSA crash-data systems page].\n- **Geographic Fragmentation**: No unified Canada-wide system; Toronto pilots underreport vs. U.S. states [22][Ontario Automated Vehicle Pilot regulation and program pages].\n\n#### Rubric for Comparability Limits\n1. **Threshold Mismatch (High Impact)**: AVs report minor disengagements/crashes absent in human data, overestimating AV risk by 5x for low-severity events; adjust via severity filtering [RAND report \"Measuring Automated Vehicle Safety: Forging a Framework\" (RR2662); NHTSA ADAS Level 2 Summary Report (June 2022)].\n2. **Exposure Bias (Medium-High Impact)**: AV ODDs exclude high-risk domains (e.g., rain, >50 mph), understating human-AV differences; normalize only within shared conditions [20][1].\n3. **Data Completeness (Medium Impact)**: Redactions/underreporting affect ~30-40% of AV logs and >50% of human minor crashes; cross-verify via multiple sources [6][5][NHTSA crash-data systems page].\n4. **Sample Size (Variable Impact)**: AV miles <0.01% of human totals; prioritize operators with >10M miles (e.g., Waymo) and quantify uncertainty via CIs [1][2][CRS insight IN11749].\n\nThis rubric highlights that while AVs show promising safety gains, unaddressed gaps prevent definitive policy conclusions without standardized reporting by late 2025 [Brookings \"state of self-driving car laws\" (2018); RAND report \"Measuring Automated Vehicle Safety: Forging a Framework\" (RR2662)].\n\n### Sources\n[1] Waymo Safety Impact Hub - https://waymo.com/safety/impact/  \n[2] Kusano et al., Traffic Injury Prevention (2024) - https://www.tandfonline.com/doi/full/10.1080/15389588.2024.2380786  \n[3] Nature Communications matched case-control (2024) - https://www.nature.com/articles/s41467-024-48526-4  \n[4] Latent class analysis, Journal of Safety Research (2025) - https://www.sciencedirect.com/science/article/pii/S0022437524001634  \n[5] NHTSA SGO ADS Incident Reports CSV - https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv  \n[6] CA DMV Autonomous Vehicle Collision Reports - https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-collision-reports/  \n[7] NHTSA Cruise Consent Order (2024) - https://www.nhtsa.gov/sites/nhtsa.gov/files/2024-09/cruise-consent-order-2024-web.pdf  \n[8] DOJ Press Release Cruise DPA - https://www.justice.gov/usao-ndca/pr/cruise-admits-submitting-false-report-influence-federal-investigation-and-agrees-pay  \n[9] Waymo Swiss Re Study (2024) - https://waymo.com/blog/2024/12/new-swiss-re-study-waymo  \n[10] Waymo Research Paper Kusano et al. - https://waymo.com/research/comparison-of-waymo-rider-only-crash-data-to-human/  \n[11] NHTSA National Statistics PDF - https://cdan.nhtsa.gov/tsftables/National%20Statistics.pdf  \n[12] NHTSA Standing General Order Crash Reporting Page - https://www.nhtsa.gov/laws-regulations/standing-general-order-crash-reporting  \n[13] CA DMV Disengagement Reports - https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/disengagement-reports/  \n[14] CA DMV News Release 9M Test Miles (2024) - https://www.dmv.ca.gov/portal/news-and-media/news-releases/autonomous-vehicle-permit-holders-report-a-record-9-million-test-miles-in-california-in-12-months/  \n[15] NHTSA Consent Order Cruise Press Release - https://www.nhtsa.gov/press-releases/consent-order-cruise-crash-reporting  \n[16] NHTSA SGO ADAS Incident Reports CSV - https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADAS.csv  \n[17] Toronto PTC Collision Rates Background - https://www.toronto.ca/legdocs/mmis/2024/ex/bgrd/backgroundfile-251488.pdf  \n[18] NHTSA AV Crash Data Summary (2024) - https://archive.legmt.gov/content/Committees/Interim/2023-2024/Transportation/Meetings/241007-July-10-2024/03.020-nhtsa-av-crash-data-summary-2024-posting2.pdf  \n[19] Waymo Safety Data Hub Blog (2024) - https://waymo.com/blog/2024/09/safety-data-hub/  \n[20] IIHS Self-Driving Vehicles News (2020) - https://www.iihs.org/news/detail/self-driving-vehicles-could-struggle-to-eliminate-most-crashes  \n[21] Cruise Third-Party Findings Blog (2024) - https://getcruise.com/news/blog/2024/cruise-releases-third-party-findings-regarding-october-2/  \n[22] Toronto AV Pilot Background (2025) - https://www.toronto.ca/legdocs/mmis/2025/ie/bgrd/backgroundfile-254933.pdf  \nNHTSA Standing General Order (SGO) Third-Amended PDF (2025)  \nNHTSA ADAS Level 2 Summary Report (June 2022)  \nNHTSA Automated Vehicles Report to Congress (2023)  \nNHTSA Crash-Data Systems Page  \nCalifornia DMV Disengagement Pages, CSVs and 2023 News Release (9,068,861 miles)  \nOntario Automated Vehicle Pilot Regulation and Program Pages  \nArizona DOT Autonomous Vehicle Testing Pages  \nTexas DOT CAV Task Force Pages  \nRAND Report \"Measuring Automated Vehicle Safety: Forging a Framework\" (RR2662)  \nBrookings \"State of Self-Driving Car Laws\" (2018)  \nCRS Insight IN11749",
      "tool_call_id": "call_18345166"
    },
    "metadata": {
      "who": "tool",
      "when": "2025-11-10T04:35:10.408038+00:00",
      "synthetic": false,
      "tool_call_id": "call_18345166",
      "name": null,
      "kind": "tool_msg"
    }
  }
]